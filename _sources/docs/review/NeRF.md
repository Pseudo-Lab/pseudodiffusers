```{admonition} Information
- **Title:** NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis

- **Reference**
    - Paper:  [https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)
    - Project: [https://github.com/bmild/nerf](https://github.com/bmild/nerf)

- **Author:** Jeongin Lee

- **Last updated on May. 22, 2024**
```

# NeRF : Representing Scenes as Neural Radiance Fields for View Synthesis

[![NeRF](http://img.youtube.com/vi/JuH79E8rdKc/0.jpg)](https://www.youtube.com/watch?v=JuH79E8rdKc)

- ê¸°ì¡´ì˜ 3D object ìì²´ë¥¼ êµ¬ì„±í•˜ì—¬ ë Œë”ë§í•˜ëŠ” explicit method â†’ ì €ì¥ ìš©ëŸ‰ì´ ë§ì´ ì†Œìš”
- NeRF ëŠ” 3D object ìì²´ë¥¼ êµ¬ì„±í•˜ì§€ ì•ŠëŠ”, **synthesizing novel views**
ì¢Œí‘œë¥¼ mlpì— ë„£ì–´ í”½ì…€ ë³„ ìƒ‰ìƒ ë° ë°€ë„ ê°’ì„ ì–»ëŠ” implicit method
- **synthesizing novel views**    
    íŠ¹ì •í•œ ì¥ë©´(Scene)ì—ì„œ ì—¬ëŸ¬ ê°ë„ë¡œ ì°ì€ ì¼ë¶€ì˜ ì‚¬ì§„ë“¤ì„ ê°€ì§€ê³  ì™„ì „ ìƒˆë¡œìš´ ê°ë„ì˜ ëª¨ìŠµì„ ìœ ì¶”í•˜ëŠ” task
    

    
## 0. Abstract

- **NeRF**
    - í•œì •ëœ ìˆ˜ì˜ ì…ë ¥ ë·° ì´ë¯¸ì§€ë“¤ì„ ì‚¬ìš©
    - continous volumetric scene í•¨ìˆ˜ ìµœì í™”ë¥¼ í†µí•´  **synthesizing novel views** ì—ì„œ SOTA ë‹¬ì„±

- **Algorithm**
    - **FC layer ì‚¬ìš© (non-convolutional)**
        - **input**  : 5 ì°¨ì› ì¢Œí‘œ (ê³µê°„ì  ìœ„ì¹˜$(x, y, z)$ & ë°”ë¼ë³´ëŠ” ë°©í–¥$(\theta, \phi))$
        - **output** : volume densityì™€ í•´ë‹¹ ë°©í–¥ì— ëŒ€í•œ ìƒ‰ìƒ ê°’
    - 5 ì°¨ì› ì¢Œí‘œ ì…ë ¥ â†’ ì¹´ë©”ë¼ ê´‘ì„ ì„ ë”°ë¼ RGB ê°’, Volume density ì˜ˆì¸¡ 
    â†’ ê³ ì „ì  Volume rendering ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ image ë¡œ í•©ì„±

- ë³µì¡í•œ êµ¬ì¡° ë° ì™¸í˜•ì„ ê°–ëŠ” scene ì— ëŒ€í•œ **Novel views rendering** ì„ ìœ„í•´ **NeRF** ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì œì‹œ (+ Positional Encoding, Hierarchical volume sampling)

- ì‹¤í—˜ì„ í†µí•´ ê¸°ì¡´ ì‘ì—…ì„ ëŠ¥ê°€í•˜ëŠ” ê²°ê³¼ë¥¼ ì…ì¦

- **Keywords :** scene representation, view synthesis, image-based rendering, 
                   volume rendering, 3D deep learning
    
    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled.png" alt="NeRF" class="bg-primary mb-1" width="800px">

    method that optimizes a continuous 5D neural radiance field representation \  (source: {https://arxiv.org/pdf/2003.08934v2})
    :::
    

    
## 1. Introduction

ìº¡ì²˜ëœ ì´ë¯¸ì§€ë“¤ì˜ ë Œë”ë§ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì—°ì†ì ì¸ $5 \mathrm{D}$ scene í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì§ì ‘ ìµœì í™”í•˜ì—¬ View synthesis ë¶„ì•¼ì˜ ì˜¤ëœ ë¬¸ì œë¥¼ ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ í•´ê²°í•¨

---

- **ì •ì  ì¥ë©´ â†’ ì—°ì†ì ì¸ $5 \mathrm{D}$ í•¨ìˆ˜ë¡œ í‘œí˜„**
    - FC layer = Regression Function  : 
    a single $5 \mathrm{D}$ coord $(x, y, z, \theta, \phi)$ â†’ density, view-dependent RGB color
    
- **Output**
    - ê³µê°„ ìƒì˜ ê° ì§€ì  $(x, y, z)$ì—ì„œ ê° ë°©í–¥ $(\theta, \phi)$ ìœ¼ë¡œ ë°©ì¶œëœ ìƒ‰ìƒ
    - ê° ì§€ì  $(x, y, z)$ ì˜ ë°€ë„(density) = $\sigma$
        - ë°€ë„ì˜ ëˆ„ì ê°’ì„ í†µí•´ ì–¼ë§ˆë‚˜ ë§ì€ ë¹›ì´ $(ğ‘¥,ğ‘¦,ğ‘§)$ ë¥¼ í†µê³¼í•˜ëŠ” ê´‘ì„ ì— ì˜í•´ ëˆ„ì ë˜ëŠ”ì§€ë¥¼ í‘œí˜„

--- 

- **íŠ¹ì • ì‹œì ìœ¼ë¡œë¶€í„°ì˜ NeRF ë Œë”ë§**

    1. ê´‘ì„ ì„ ë”°ë¼ ì´ë™í•˜ì—¬ ìƒ˜í”Œë§ëœ $3 \mathrm{D}$ í¬ì¸íŠ¸ ì§‘í•©ì„ ìƒì„±
    2. í•´ë‹¹ í¬ì¸íŠ¸ë“¤ê³¼ ì´ì— í•´ë‹¹í•˜ëŠ” $2 \mathrm{D}$ ì‹œì  ë°©í–¥ì„ ì‹ ê²½ë§ì— ëŒ€í•œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìƒ‰ìƒê³¼ ë°€ë„ì˜ ì§‘í•©ì„ ìƒì„±
    3. ê³ ì „ì  Volume rendering ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ $2 \mathrm{D}$ image ë¡œ í•©ì„± 
    
---
    
- **Optimization**
    - ë¯¸ë¶„ ê°€ëŠ¥, gradient descent ë¥¼ í†µí•œ ìµœì í™”
    - ê° ê´€ì°°ëœ ì´ë¯¸ì§€ì™€ ë Œë”ë§ëœ í•´ë‹¹ **views**ì‚¬ì´ì˜ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”
    - ë‹¤ì–‘í•œ views ì—ì„œ ì˜¤ì°¨ ìµœì†Œí™”ë¥¼ í†µí•´ ì‹¤ì œ ì¥ë©´ì˜ cotents ê°€ í¬í•¨ëœ ìœ„ì¹˜ì— **ë†’ì€ ë°€ë„**ì™€ **ì •í™•í•œ ìƒ‰ìƒ**ì„ í• ë‹¹í•˜ì—¬ ì¥ë©´ì˜ ì¼ê´€ëœ ëª¨ë¸ì„ ì˜ˆì¸¡

---

- **NeRF ìµœì í™”ì˜ Basic implementationì˜ í•œê³„ ë° ëŒ€ì•ˆ**
    1. **ë³µì¡í•œ ì¥ë©´ì— ëŒ€í•´ì„œ ì¶©ë¶„íˆ ê³ í•´ìƒë„ í‘œí˜„ìœ¼ë¡œ ìˆ˜ë ´ë˜ì§€ ì•ŠìŒ**
        - positional encoding ìœ¼ë¡œ ì…ë ¥ 5D ì¢Œí‘œë¥¼ ë³€í™˜
        - MLPê°€ ë” ë†’ì€ ì£¼íŒŒìˆ˜ì˜ í•¨ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŒ.
    2. **ì¹´ë©”ë¼ ê´‘ì„ ë‹¹ ìš”êµ¬ë˜ëŠ” ìƒ˜í”Œë§ ìˆ˜ê°€ ë¹„íš¨ìœ¨ì **
        - ê³„ì¸µì  ìƒ˜í”Œë§ ì ˆì°¨ë¥¼ ì œì•ˆ
        - ê³ ì£¼íŒŒìˆ˜ì˜ ì¥ë©´ í‘œí˜„ì„ ì ì ˆí•˜ê²Œ ìƒ˜í”Œë§í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì¿¼ë¦¬ ìˆ˜ë¥¼ ê°ì†Œì‹œí‚´

---

- **ë³¸ ë…¼ë¬¸ì˜ ì ‘ê·¼ ë°©ì‹ì€ volumetric í‘œí˜„ì˜ ì´ì ì„ ìƒì†**
    - ë³µì¡í•œ ì‹¤ì„¸ê³„ì˜ ê¸°í•˜í•™ì  í˜•íƒœì™€ ì™¸í˜•ì„ í‘œí˜„ ê°€ëŠ¥
    - íˆ¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ Gradient-based ìµœì í™”ì— ì í•©
    - ê³ í•´ìƒë„ì—ì„œ ë³µì¡í•œ ì¥ë©´ì„ ëª¨ë¸ë§í•  ë•Œ ì´ì‚°í™”ëœ ë³µì…€ ê·¸ë¦¬ë“œì˜ ì—„ì²­ë‚œ ì €ì¥ ë¹„ìš©ì„ ê·¹ë³µ

    - **Voxel (Volume + Pixel)**
    3ì°¨ì› ê³µê°„ì—ì„œ ì²´ì ì˜ ê¸°ë³¸ ë‹¨ìœ„ (2ì°¨ì›ì˜ ê²½ìš°ì—ì„  pixe)
    ìœ„ì¹˜ ì •ë³´ì™€ í•¨ê»˜ ë°€ë„, ìƒ‰ìƒ, íˆ¬ê³¼ì„± ë“±ì˜ ì†ì„±ì„ ê°€ì§ˆ ìˆ˜ ìˆìŒ
    
    - **Volumne Rendering**
    3ì°¨ì› ê³µê°„ì—ì„œ ì •ì˜ëœ ë°ì´í„°(ì²´ì  ë°ì´í„°)ë¥¼ 2ì°¨ì› ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì • 
    ì˜ˆì‹œ) CT, MRI 
    
    - **Volumetric Data (ì²´ì  ë°ì´í„°)**
    3ì°¨ì› ê³µê°„ì—ì„œ ìƒ˜í”Œë§ëœ ë°ì´í„°


---


- **Technical contributions**
    - ë³µì¡í•œ ê¸°í•˜í•™ê³¼ ì†Œì¬ë¥¼ ê°€ì§„ ì—°ì†ì ì¸ ì¥ë©´ì„ 5ì°¨ì› NeRF ë¡œ ë‚˜íƒ€ë‚´ëŠ” ì ‘ê·¼ ë°©ë²•, ê¸°ë³¸ MLP ë„¤íŠ¸ì›Œí¬ë¡œ ë§¤ê°œë³€ìˆ˜í™”
    - ê³ ì „ì ì¸ ë³¼ë¥¨ ë Œë”ë§ ê¸°ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¯¸ë¶„ ê°€ëŠ¥í•œ ë Œë”ë§ ì ˆì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ í‘œí˜„ì„ í‘œì¤€ RGB ì´ë¯¸ì§€ë¡œë¶€í„° ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆ
    - hierarchical sampling strategy : MLPâ€™s capacity ë¥¼ ì‹œê°ì ì¸ ì¥ë©´ ë‚´ìš©ì´ ìˆëŠ” ê³µê°„ìœ¼ë¡œ í• ë‹¹ (ë¬¼ì²´ê°€ ìˆì„ í™•ë¥ ì´ ë†’ì€ ë¶€ë¶„ì„ ëª¨ë¸ì´ ì§‘ì¤‘ì ìœ¼ë¡œ í•™ìŠµ)
    - Positional encoding : ì…ë ¥ 5ì°¨ì› ì¢Œí‘œë¥¼ ê³ ì°¨ì› ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•´ NeRFë¥¼ ì„±ê³µì ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ ê³ ì£¼íŒŒì˜ ì¥ë©´ ì½˜í…ì¸ ë¥¼ í‘œí˜„ê°€ëŠ¥
- ìµœì´ˆì˜ **continuous neural scene representation** ì œì•ˆ

:::{figure-md} 
<img src="../../pics/NeRF/Untitled1.png" alt="NeRF overview" class="bg-primary mb-1" width="800px">

An overview of our neural radiance field scene representation and differentiable rendering procedure \  (source: {https://arxiv.org/pdf/2003.08934v2})
:::
    

   
## 2. Related Work

- **Neural 3D shape representations**
- **View synthesis and image-based rendering**
    

   
## 3. Neural Radiance Field Scene Representation

- 5ì°¨ì› ë²¡í„° í•¨ìˆ˜ (MLP) $F_{\Theta}:(\mathbf{x}, \mathbf{d}) \rightarrow(\mathbf{c}, \sigma)$

    - **input** : $3 \mathrm{D}$ location $\mathbf{x}=(x, y, z)$ , $2 \mathrm{D}$ viewing direction $\mathbf{d}=(\theta, \phi)$
        - **(practically) direction** as a $3 \mathrm{D}$ Cartesian unit vector $\mathbf{d}$
        - ë²¡í„° $\mathbf{d} =(ğ‘‘_ğ‘¥,ğ‘‘_ğ‘¦,ğ‘‘_ğ‘§)$ ëŠ” ë°©í–¥ì„ ë‚˜íƒ€ë‚´ë©°, ì´ëŠ” ë‹¨ìœ„ ë²¡í„°(ê¸¸ì´ê°€ 1)ë¡œ ì •ê·œí™”
    - **output** : emitted color $\mathbf{c}=(r, g, b)$, volume density $\sigma$

- $\mathbf{x}$ â†’Â $\sigma$ , $(\mathbf{x, d})$ â†’ RGB ìƒ‰ìƒÂ $\mathbf{c}$ ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ê¶Œì¥ (ìƒ‰ìƒì€ view dependent ì´ë¯€ë¡œ)

    1.  MLPÂ $F_{\Theta}$ ëŠ” ë¨¼ì € 8ê°œì˜ fully-connected layer (ReLU, 256ê°œ ì±„ë„ ì‚¬ìš©) ë¡œ 
    ì…ë ¥ 3D ì¢Œí‘œÂ $\mathbf{x}$ â†’ Â $\sigma$ , 256ì°¨ì› feature ë²¡í„°ë¥¼ ì¶œë ¥
    2. **a** ì˜ feature ë²¡í„°ëŠ” ì¹´ë©”ë¼ ê´‘ì„ ì˜ ì‹œì  ë°©í–¥ê³¼ concat 
    3. ë·°ì— ë”°ë¥¸ RGB ìƒ‰ìƒì„ ì¶œë ¥í•˜ëŠ” í•˜ë‚˜ì˜ ì¶”ê°€ fully-connected layer (ReLU,128ê°œ ì±„ë„ ì‚¬ìš©)ë¡œ ì „ë‹¬ë¨
        
    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled3.png" alt="NeRF architecture" class="bg-primary mb-1" width="800px">

    fully-connected network architecture\  (source: {https://arxiv.org/pdf/2003.08934v2})
    :::


- **View ë¥¼ ê³ ë ¤í•˜ì—¬ ìƒ‰ìƒì„ ì˜ˆì¸¡í•´ì•¼ í•˜ëŠ” ì´ìœ  : non-Lambertian effects**
    - **Lambertian íš¨ê³¼**
        - ë¬¼ì²´ì˜ í‘œë©´ì—ì„œ ë‚˜ì˜¤ëŠ” ê´‘ì„ ì´ ê· ì¼í•˜ê²Œ ë°˜ì‚¬ë˜ëŠ” í˜„ìƒ
        - í‘œë©´ì˜ ë°©í–¥ê³¼ ìƒê´€ì—†ì´ ê´‘ì„ ì´ í‘œë©´ì—ì„œ ë‚˜ì˜¤ëŠ” ê°ë„ì— ë”°ë¼ ë°˜ì‚¬ë˜ëŠ” ê´‘ëŸ‰ì´ ì¼ì •í•˜ë‹¤ëŠ” ì›ë¦¬ë¥¼ ê¸°ë°˜
    - Fig. 3 : ì…ë ¥ ì‹œì„  ë°©í–¥ì„ ì‚¬ìš©í•˜ì—¬ non-Lambertian effects ë¥¼ í‘œí˜„í•œ ì˜ˆì‹œ
    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled4.png" alt="NeRF fig3" class="bg-primary mb-1" width="800px">
    
    :::

    - Fig. 4 : view dependence ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³  (only $\mathbf{x}$ input) í•™ìŠµëœ ëª¨ë¸ì€ ë°˜ì‚¬ì„±(specularity)ì„ í‘œí˜„í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆìŒ
    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled5.png" alt="NeRF fig4" class="bg-primary mb-1" width="800px">

    :::
    

   
## 4. Volume Rendering with Radiance Fields

- **5D NeRF ëŠ” ì¥ë©´ì„ volume density ì™€ íŠ¹ì • í¬ì¸íŠ¸ì—ì„œ ë°©ì¶œëœ ë¹›(ìƒ‰ìƒ)ìœ¼ë¡œ í‘œí˜„**
- **ë³¼ë¥¨ ë Œë”ë§ : scene ì„ í†µê³¼í•˜ëŠ” ëª¨ë“  ê´‘ì„ ì˜ ìƒ‰ìƒì„ ë Œë”ë§**
    - NeRF ë¡œë¶€í„° View ë¥¼ ë Œë”ë§í•˜ë ¤ë©´ ì›í•˜ëŠ” ê°€ìƒ ì¹´ë©”ë¼ì˜ ê° í”½ì…€ì„ ê±°ì³ ì¶”ì ëœ ì¹´ë©”ë¼ ê´‘ì„ ì— ëŒ€í•´ ì ë¶„ê°’  $C(\mathbf{r})$ ì„ ì¶”ì •ì„ ìš”êµ¬
    - $\mathbf{r}(t)=\mathbf{o}+t \mathbf{d}$ : ì¹´ë©”ë¼ ê´‘ì„ 
    - $C(\mathbf{r})$ : near bound $t_n$ , far bound $t_f$ ì—ì„œ ì¹´ë©”ë¼ ê´‘ì„  $\mathbf{r}(t)$ ì˜ ì˜ˆì¸¡ëœ ìƒ‰ìƒ
    - $T(t)$ : ray ë¥¼ ë”°ë¼ $t_n$ ë¶€í„° $t$ ê¹Œì§€ ëˆ„ì ëœ íˆ¬ê³¼ìœ¨(transmittance)

$$
C(\mathbf{r})=\int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t)) \mathbf{c}(\mathbf{r}(t), \mathbf{d}) d t, \text { where } T(t)=\exp \left(-\int_{t_n}^t \sigma(\mathbf{r}(s)) d s\right)
$$

- **Quadrature (êµ¬ì ë²•) ì„ í†µí•´ ì—°ì†ì  ì ë¶„ê°’ì„ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì¶”ì •**
    - ì´ì‚°í™”ëœ ****voxel grids ë Œë”ë§ì— ì‚¬ìš©ë˜ëŠ” **ê²°ì •ë¡ ì  êµ¬ì ë²•**ì˜ í•œê³„
    - ì¼ë°˜ì ìœ¼ë¡œ ì´ì‚°í™”ëœ ë³µì…€ ê·¸ë¦¬ë“œë¥¼ ë Œë”ë§í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê²°ì •ë¡ ì  êµ¬ì ë²•ì€ MLPê°€ **ê³ ì •ëœ ì´ì‚° ìœ„ì¹˜ ì§‘í•©**ì—ì„œë§Œ ì¿¼ë¦¬ë˜ê¸° ë•Œë¬¸ì— í‘œí˜„ì˜ í•´ìƒë„ë¥¼ ì œí•œ


- â¡ï¸ **ëŒ€ì•ˆìœ¼ë¡œ Stratified sampling (ê³„ì¸µì  í‘œì§‘) ì ‘ê·¼ë²•ì„ ì‚¬ìš©.**
- $\left[t_n, t_f\right]$ ë¥¼ $N$ ê°œì˜ ê· ì¼í•œ ê°„ê²©ì˜ binìœ¼ë¡œ ë¶„í• í•œ Partition ìƒì„±
- ê° bin ë‚´ì—ì„œ í•˜ë‚˜ì˜ ìƒ˜í”Œì„ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œ
    
    $$
    t_i \sim \mathcal{U}\left[t_n+\frac{i-1}{N}\left(t_f-t_n\right), t_n+\frac{i}{N}\left(t_f-t_n\right)\right].
    $$

- ì—¬ì „íˆ ì ë¶„ê°’ ì¶”ì •ì„ ìœ„í•´ ì´ì‚°í™”ëœ í‘œë³¸ë“¤ì„ ì‚¬ìš©í•˜ë”ë¼ë„, 
ê³„ì¸µì  í‘œì§‘ ë°©ë²•ì„ í†µí•´ continuous scene í‘œí˜„ì´ ê°€ëŠ¥
- ë‹¤ì–‘í•œ position sampleì— ëŒ€í•´ ìµœì í™”ê°€ ê°€ëŠ¥í•˜ë¯€ë¡œ, ìµœì í™” ê³¼ì •ì—ì„œ MLPê°€ ì—°ì†ì ì¸ ìœ„ì¹˜ë“¤ì—ì„œ í‰ê°€ë˜ë„ë¡ í•˜ëŠ” íš¨ê³¼


- ìœ„ì˜ ìƒ˜í”Œë§ ë°©ë²•ì„ í†µí•´ ë½‘ì€ ìƒ˜í”Œë“¤ë¡œ  [[26]ì—ì„œ ë¦¬ë·°](https://courses.cs.duke.edu/spring03/cps296.8/papers/max95opticalModelsForDirectVolumeRendering.pdf)ëœ ë³¼ë¥¨ ë Œë”ë§ì—ì„œ ë…¼ì˜ëœ êµ¬ì ë²•ìœ¼ë¡œ $C(\mathbf{r})$ ì„ ì¶”ì • (ì ë¶„ì„ sample sum ìœ¼ë¡œ)
    
    $$
    \hat{C}(\mathbf{r})=\sum_{i=1}^N T_i\left(1-\exp \left(-\sigma_i \delta_i\right)\right) \mathbf{c}_i, \\ \text { where } T_i=\exp \left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right),
    $$
    
    - $\delta_i=t_{i+1}-t_i$ is the distance between adjacent samples ($dt$ ë¥¼ ëŒ€ì²´)
    - $\left(\mathbf{c}_i, \sigma_i\right)$ ì˜ ì§‘í•©ìœ¼ë¡œë¶€í„° $\hat{C}(\mathbf{r})$ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ëŠ” ì‰½ê²Œ ë¯¸ë¶„ ê°€ëŠ¥í•˜ë©° 
    $\alpha_i=1-\exp \left(-\sigma_i \delta_i\right)$ ë¥¼ ì‚¬ìš©í•œ ì „í†µì ì¸ **alpha compositing**
    - **alpha compositing (**ì•ŒíŒŒ í•©ì„±)
        - ì—¬ëŸ¬ ì´ë¯¸ì§€ ë˜ëŠ” í”½ì…€ì„ ê²°í•©í•˜ì—¬ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¡œ ë§Œë“œëŠ” ê¸°ìˆ 
        - ex) íˆ¬ëª…í•œ ì´ë¯¸ì§€(ìœ ë¦¬, ê·¸ë¦¼ì)ë¥¼ ë°°ê²½ ì´ë¯¸ì§€ ìœ„ì— ê²¹ì¹  ë•Œ ì•ŒíŒŒ ì»´í¬ì§€íŒ…ì„ ì‚¬ìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„± ìˆ˜í–‰
    

   
## 5. Optimizing a Neural Radiance Field

**[REMIND]**

- ì§€ê¸ˆê¹Œì§€ **NeRF ë¡œ scene ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒ, ì´ í‘œí˜„ìœ¼ë¡œ ìƒˆë¡œìš´ views ë¥¼ ë Œë”ë§ í•˜ëŠ” ê²ƒ** ì— í•„ìš”í•œ í•µì‹¬ì ì¸ êµ¬ì„±ìš”ì†Œë¥¼ ë‹¤ë£¸
    - í•˜ì§€ë§Œ í•´ë‹¹ ìš”ì†Œë“¤ë¡œ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸°ì—ëŠ” í•œê³„ ì¡´ì¬
    - ê³ í•´ìƒë„ + ë³µì¡í•œ scene ì„ í‘œí˜„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë‘ê°œì˜ ê°œì„ ì ì„ ë„ì…

1. Positional encoding of the input coordinates 
that assists the MLP in representing high-frequency functions 
2. hierarchical sampling procedure 
that allows us to efficiently sample this high-frequency representation.

### 5.1 Positional encoding

- Neural network $F_{\Theta}$ ê°€ ì§ì ‘ **$(x, y, z, \theta, \phi)$ input coordinates** ì—ì„œ ì§ì ‘ ì—°ì‚°í•˜ëŠ” ê²½ìš°, ìƒ‰ìƒê³¼ í˜•íƒœì—ì„œ ê³ ì£¼íŒŒ ë³€ë™ì„ í‘œí˜„í•˜ëŠ”ë° ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ìŒ
- [[35] On the spectral bias of neural networks](https://arxiv.org/abs/1806.08734) ë…¼ë¬¸ ê²°ê³¼ì™€ ë™ì¼,
    - ê¹Šì€ ì‹ ê²½ë§ì´ ì €ì£¼íŒŒ í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ìª½ìœ¼ë¡œ í¸í–¥ë˜ì—ˆìŒì„ ë³´ì—¬ì¤Œ
    - ì‹ ê²½ë§ì„ í†µê³¼í•˜ê¸° ì „ ê³ ì£¼íŒŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì…ë ¥ì„ ê³ ì°¨ì› ê³µê°„ìœ¼ë¡œ ë§µí•‘**í•˜ëŠ” ê²ƒì€ ê³ ì£¼íŒŒ ë³€ë™ì´ í¬í•¨ëœ ë°ì´í„°ë¥¼ ë” ì˜ ì í•© ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ì œì‹œ
    - ì €ìë“¤ì€ Neural scene representations ì—ì„œ ìœ„ì˜ ê²°ê³¼ë¥¼ ì´ìš©
- **â†’ $F_{\Theta}$ ë¥¼ ë‘ê°œì˜ í•¨ìˆ˜ë¡œ  êµ¬ì„± $F_{\Theta}=F_{\Theta}^{\prime} \circ \gamma$  ì„±ëŠ¥ì„ ìƒë‹¹íˆ ê°œì„  ($\gamma$ : í•™ìŠµ X)**
    
    $$
    \gamma(p)=\left(\sin \left(2^0 \pi p\right), \cos \left(2^0 \pi p\right), \cdots, \sin \left(2^{L-1} \pi p\right), \cos \left(2^{L-1} \pi p\right)\right) .
    $$
    
    - $\gamma$ : mapping $\mathbb{R}$ â†’ $\mathbb{R}^{2 L}$, $F_{\Theta}^{\prime}$ : Regular MLP
    - $\gamma(\cdot)$ : $\mathbf{x}$ ì˜ ê° ì„¸ê°œì˜ ì¢Œí‘œê°’ê³¼  Cartesian ì‹œì  ë°©í–¥ ë²¡í„° $\mathbf{d}$ ì˜ ì„¸ ì„±ë¶„ì— $[-1,1]$ì‚¬ì´ë¡œ ì •ê·œí™” í›„ ê°œë³„ì ìœ¼ë¡œ ì ìš©ì— ë¶„ë¦¬ë˜ì–´ ì ìš©ë¨
    - Experiments : $L=10$ for $\gamma(\mathbf{x})$ and $L=4$ for $\gamma(\mathbf{d})$
    

### 5.2 Hierarchical volume sampling

- **Stratified Sampling**
    - ë¹„íš¨ìœ¨ì 
    - ë Œë”ë§ëœ ì´ë¯¸ì§€ì— ê¸°ì—¬í•˜ì§€ ì•ŠëŠ” ì—¬ìœ  ê³µê°„(ë¹„ì–´ìˆëŠ” ë¶€ë¶„) ë§‰í˜€ìˆëŠ”(ê°€ë ¤ì§„) ì˜ì—­ì´ ì—¬ì „íˆ ë°˜ë³µì ìœ¼ë¡œ ìƒ˜í”Œë§ë¨.
- **Hierarchical volume sampling**
    - ìµœì¢… ë Œë”ë§ì— ëŒ€í•œ ì˜ˆìƒ íš¨ê³¼ì— ë¹„ë¡€í•˜ì—¬ ìƒ˜í”Œì„ í• ë‹¹
    - ë Œë”ë§ íš¨ìœ¨ì„±ì„ ì¦ê°€ì‹œí‚´
    
    **â¡ï¸ Contentê°€ ë” ìˆì„ ê²ƒ ê°™ì€ ê³³ì„ ë” ë½‘ì !**
    
- scene í‘œí˜„ì„ ìœ„í•´ ë‹¨ìˆœíˆ ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ëŒ€ì‹ ì— ìš°ë¦¬ëŠ” ë™ì‹œì— 2ê°œì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ìµœì í™”
    
    **Step 1. Coarse**
    
    **Step 2.  Fine** 
    
---

1. **Coarse**
    
    **Stratified sampling** â†’ $N_c$ ê°œì˜ ìœ„ì¹˜ ì§‘í•©ì„ ìƒ˜í”Œë§, ì´ ìœ„ì¹˜ì—ì„œ $\hat{C(r)}$ ì„ ì˜ˆì¸¡í•˜ì—¬ **Coarse network** ë¥¼  í‰ê°€
    
2. **Fine** 
    1. 1ì—ì„œ ì£¼ì–´ì§„ Coarse ë„¤íŠ¸ì›Œí¬ì˜ ì¶œë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë” ë§ì€ ì •ë³´ì— ê¸°ë°˜í•œ í¬ì¸íŠ¸ ìƒ˜í”Œë§ì„ ìƒì„± (ë” ë§ì€ ì •ë³´ì— ê¸°ë°˜í•œ í¬ì¸íŠ¸ ìƒ˜í”Œë§ì„ ìƒì„±)
    2. Coarse ë„¤íŠ¸ì›Œí¬ì—ì„œì˜ ì•ŒíŒŒ í•©ì„± ìƒ‰ìƒ $\hat{C}_c(\mathbf{r})$ì„ ê´‘ì„ ì„ ë”°ë¼ ìƒ˜í”Œë§ëœ ëª¨ë“  ì»¬ëŸ¬ $c_i$ë“¤ì˜ ê°€ì¤‘í•© í˜•íƒœë¡œ ë‹¤ì‹œ ì”€ 
        
        $$
        \hat{C}_c(\mathbf{r})=\sum_{i=1}^{N_c} w_i c_i, \quad w_i=T_i\left(1-\exp \left(-\sigma_i \delta_i\right)\right) .
        $$
        
3. **piecewise-constant PDF**
    
    Normalizing weight ë¥¼ í†µí•´ ìƒì„±
    

$$
\hat{w}i= \dfrac{w_i}{\sum_{j=1}^{N_c} w_j}
$$

- ì—­ë³€í™˜ ìƒ˜í”Œë§ì„ í†µí•´ í™•ë¥  ë°€ë„í•¨ìˆ˜ ê°’ì— ê¸°ë°˜í•œ 2ë²ˆì§¸ ìƒ˜í”Œì§‘í•©ì˜ ìƒ˜í”Œ $N_f$ ê°œë¥¼ ìƒ˜í”Œë§
- ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ìƒ˜í”Œ ì§‘í•©ì˜ í•©ì§‘í•©ì—ì„œ fine ë„¤íŠ¸ì›Œí¬ë¥¼ í‰ê°€
- ëª¨ë“ Â $N_c+N_f$ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì—¬ ê´‘ì„ ì˜ ìµœì¢… ë Œë”ë§ëœ ìƒ‰ìƒÂ $\hat{C}_f(\mathbf{r})$ ë¥¼ ê³„ì‚°
- ì´ ì ˆì°¨ì—ì„œëŠ” ê´€ì¸¡ ê°€ëŠ¥í•œ contentê°€ í¬í•¨ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì˜ì—­ì— ë” ë§ì€ ìƒ˜í”Œì„ í• ë‹¹

### 5.3 Implementation details

- **ê° Scene ì— ëŒ€í•´ ë„¤íŠ¸ì›Œí¬ ë¥¼ ë³„ë„ë¡œ ìµœì í™”**
    
    sceneì´ ìº¡ì²˜ëœ RGB ì´ë¯¸ì§€, extrinsic parameter(í•´ë‹¹ ì¹´ë©”ë¼ í¬ì¦ˆ), intrinsic parameter, ì¥ë©´ ê²½ê³„ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì´ í•„ìš” 
    
    - **extrinsic parameter, intrinsic parameter**
        
        - **Extrinsic Parameter**        
         3DÂ ê³µê°„ ë‚´ì—ì„œ ì¹´ë©”ë¼ê°€ ì–´ë””ì— ìœ„ì¹˜(3D Translation)í•˜ê³  ìˆê³ ,Â ì–´ë””ë¥¼ ë°”ë¼ë³´ê³  ìˆëŠ”ì§€(3D Rotation)ì— ëŒ€í•œÂ Parameter
        
        - **Intrinsic Parameter**
        ì¹´ë©”ë¼ ë Œì¦ˆì™€ ì„¼ì„œ ìœ„ì¹˜ì— ì˜í•´ì„œ ê²°ì •ë˜ì–´ì§€ëŠ” í•­ëª©ìœ¼ë¡œ, ì´ë¯¸ì§€ íŒ¨ë„ì´ ì–¼ë§ˆë‚˜ ì´ë™(2D Translation)í•˜ê³ ,Â ì–¼ë§ˆë‚˜ í™•ëŒ€í•˜ê³ (2D Scaling),Â ì–¼ë§ˆë‚˜ ê¸°ìš¸ì–´ì¡ŒëŠ”ì§€(2DÂ Shear)Â ëŒ€í•œÂ intrinsic parameter
        
        :::{figure-md} 
        <img src="../../pics/NeRF/Untitled6.png" alt="NeRF intrinsic_extrinsic" class="bg-primary mb-1" width="800px">

        intrinsic prameter and extrinsic parameter
        :::

        - ì¹´ë©”ë¼ ì˜ìƒ : 3ì°¨ì› ê³µê°„ìƒì˜ ì ë“¤ì„ 2ì°¨ì› ì´ë¯¸ì§€ í‰ë©´ì— íˆ¬ì‚¬(perspective projection)
        :::{figure-md} 
        <img src="../../pics/NeRF/Untitled7.png" alt="NeRF perspective projection" class="bg-primary mb-1" width="800px">
            
        perspective projection
        :::
            
- **Training**

    1. ê° ìµœì í™” iterationì—ì„œ ë°ì´í„°ì…‹ì˜ ëª¨ë“  í”½ì…€ ì§‘í•©ì—ì„œ ì¹´ë©”ë¼ ê´‘ì„  batchë¥¼ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§
    2. ê³„ì¸µì  ìƒ˜í”Œë§ì„ ë”°ë¼ coarse ë„¤íŠ¸ì›Œí¬ì˜Â $N_c$ ê°œì˜ ìƒ˜í”Œê³¼ fine ë„¤íŠ¸ì›Œí¬ì˜$N_c + N_f$ê°œì˜ ìƒ˜í”Œì„ ì¿¼ë¦¬
    3. volume rendering ì ˆì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ìƒ˜í”Œ ì§‘í•© ëª¨ë‘ì—ì„œ ê´‘ì„ ì˜ ìƒ‰ìƒì„ ë Œë”ë§

- **Loss**
    coarse ë Œë”ë§ê³¼ fine ë Œë”ë§ì˜ ìƒ‰ìƒ vs ì‹¤ì œ í”½ì…€ ìƒ‰ìƒ ê°„ì˜ ì´ ì œê³± ì˜¤ì°¨ 
    
    $$
    \mathcal{L}=\sum_{\mathbf{r} \in \mathcal{R}}\left[\left\|\hat{C}_c(\mathbf{r})-C(\mathbf{r})\right\|_2^2+\left\|\hat{C}_f(\mathbf{r})-C(\mathbf{r})\right\|_2^2\right]
    $$
    
    - $\mathcal{R}$ : ê° batch ì˜ ê´‘ì„ ì˜ ì§‘í•©
    - $C(\mathbf{r})$  : Ray $\mathbf{r}$ ì— ëŒ€í•œ Ground Truth RGB colors
    - $\hat{C}_c(\mathbf{r})$ : Ray $\mathbf{r}$ ì— ëŒ€í•œ Coarse volume predicted RGB colors
    - $\hat{C}_f(\mathbf{r})$ : Ray $\mathbf{r}$ ì— ëŒ€í•œ Fine volume predicted RGB colors
    - ìµœì¢… ë Œë”ë§ì€  $\hat{C}_f(\mathbf{r})$ ì´ì§€ë§Œ, $\hat{C}_c(\mathbf{r})$ ì˜ Loss ì—­ì‹œ ìµœì†Œí™”
        - Coarse ë„¤íŠ¸ì›Œí¬ì˜ weight ë¶„í¬ê°€ fine network ì˜ ìƒ˜í”Œë§ì˜ ê¸°ë°˜ì´ ë˜ê¸° ë•Œë¬¸

## 5.4 Experiments detail

- a batch size of 4096 rays
- sampling coordinates :
    - $N_c=64$ in the coarse volume
    - $N_f=128$ in the fine volume
- Optimizer : Adam, lr : $5 \times 10^{-4}$ â†’  $5 \times 10^{-5}$ (exponentially decay learning rate)
    - Default : $\beta_1=0.9, \beta_2=0.999$,
- iteration: í•œ ì¥ë©´ ë‹¹ 10~30ë§Œ iter (NVIDIA V100 GPU 1ê°œë¡œ 1~2ì¼ ì†Œìš”)
    

   
## 6. Results

### 6.1 Datasets

- **Synthetic renderings of object**
        :::{figure-md} 
        <img src="../../pics/NeRF/Untitled8.png" alt="Diffuse Synthetic" class="bg-primary mb-1" width="800px">
        
        Diffuse Synthetic : Lambertian, Realistic Synthetic : non-Lambertian
        :::

1. **Diffuse / Synthetic** $360\degree$

    1. ì´ 4ê°œì˜ Lambertian ë¬¼ì²´ê°€ ê°„ë‹¨í•œ geometryë¡œ êµ¬ì„±
    2. object : **512Ã—512** 
    3. ìƒë°˜êµ¬ì— ëŒ€í•œ viewpoint ë¥¼ ë Œë”ë§
    4. Train : 479, Test : 1000

2. **Real / Synthetic $360\degree$, Forward-Facing** 

    1. ì´ 8ê°œì˜ non-Lambertian ë¬¼ì²´ 8ê°œ, 
    2. ê°ê°ì˜ pathtraced image ë¥¼ í¬í•¨í•œ í˜•íƒœì˜ ë°ì´í„° ì…‹ì„ êµ¬ì„±
    3. object : **800Ã—800**
    4. 6 Scenes : ìƒë°˜êµ¬ì— ëŒ€í•œ viewpoint ë¥¼ ë Œë”ë§, 2 Scenes :  êµ¬ ì „ì²´ì— ëŒ€í•œ viewpoint ë¥¼ ë Œë”ë§
    5. Train : 100, Test : 200

3. **Real / Forward-Facing** 

    1. ë³µì¡í•œ í˜•íƒœì˜ í˜„ì‹¤ sceneì„ ì•ìª½ì—ì„œ ë³¸ ëª¨ìŠµì„ ì‚¬ìš©
    2. ì´ 8ê°œì˜ scene, (5 scenes : LLFF paper 3 scenes : ì§ì ‘ ìº¡ì²˜)
    3. object : **$1008\times 756$** 
    4. Train : Test = 7 : 1

### 6.2 Comparisons

- **Models**
    - **Neural Volumes (NV)**
    - **Scene Representation Networks (SRN)**
    - **Local Light Field Fusion (LLFF)**

### 6.3 Discussion

1. comparison : Diffuse Synthetic : Lambertian, Realistic Synthetic : non-Lambertian
- $\text{Nerf}$ : ë¯¸ì„¸ ë””í…Œì¼, ê¸°í•˜í•™ì  êµ¬ì¡°, ì™¸ì–‘, nonLambertian ë°˜ì‚¬ ë°˜ì˜
- $\text{LLFF}$ :  ghosting artifact (ship, lego)
- $\text{SRN}$ : blurry and distorted rendering
- $\text{NV}$ : detail ë° ê¸°í•˜ì  êµ¬ì¡° ë°˜ì˜ ì‹¤íŒ¨

    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled9.png" alt="Diffuse Synthetic" class="bg-primary mb-1" width="800px">

    Diffuse Synthetic : Lambertian, Realistic Synthetic : non-Lambertian
    :::

- **Ghosting :** ë Œë”ë§ì—ì„œì˜ ê°ì²´ ê²¹ì¹¨ í˜¹ì€ ë²ˆì§
- **Lambertian :** ëª¨ë“  ê°ë„ì—ì„œ ë™ì¼í•œ ë°ê¸°
- **Non-Lambertian :** ê°ë„ì— ë”°ë¼ ë°ê¸°ì™€ ìƒ‰ìƒ ë³€í™” / ê´‘íƒ, ë°˜ì‚¬, íˆ¬ëª…ë„ ë“±ì„ ê°€ì§

2. comparison : reconstruction partially occluded regions
    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled10.png" alt="Diffuse Synthetic" class="bg-primary mb-1" width="800px">

    NeRF also correctly reconstructs partially occluded regions
    :::

### 6.4 Ablation studies

- Realistic Synthetic 360ë„ scene
- ìœ„ì¹˜ ì¸ì½”ë”©(PE), ì‹œì  ì˜ì¡´ì„±(VD), ê³„ì¸µì  ìƒ˜í”Œë§(H)
- ìµœëŒ€ ì£¼íŒŒìˆ˜ $L$ ì˜ ì„ íƒ
    - 5â†’10 (ì„±ëŠ¥ í–¥ìƒ), 10â†’15 (ì„±ëŠ¥ ê°ì†Œ)
    - $2^L$ ì´ ìƒ˜í”Œë§ ëœ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì¡´ì¬í•˜ëŠ” ìµœëŒ€ ì£¼íŒŒìˆ˜(ë³¸ ë°ì´í„°ëŠ” 1024)ë¥¼ ì´ˆê³¼í•  ë•Œ  ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì— ì œí•œ

    :::{figure-md} 
    <img src="../../pics/NeRF/Untitled11.png" alt="ablation study" class="bg-primary mb-1" width="800px">

    ablation study
    :::
    

   
---

## (Appendix) A. Additional Implementation Details

1. **Volume Bounds**
For experiments with synthetic images, we scale the scene so that it lies within a **cube of
side length 2 centered at the origin**, and only query the representation within this bounding volume. we use normalized device coordinates **to map the depth range of these points into [âˆ’1, 1]**.

2. **Training Details**
adding random Gaussian noise with zero mean and unit variance to the **output Ïƒ values** during optimization

3. **Rendering Details**
        :::{figure-md} 
        <img src="../../pics/NeRF/Untitled3.png" alt="NeRF architecture" class="bg-primary mb-1" width="800px">>

        fully-connected network architecture \  (source: {https://arxiv.org/pdf/2003.08934v2})
        :::

- Coarse network  64 + fine network 128 = 192
- fully-connected network êµ¬ì¡°
- positional encodingì´ ë”í•´ì§„ í˜•íƒœì˜ ìœ„ì¹˜ ì •ë³´**$(\gamma(x))$**Â ë¥¼ inputìœ¼ë¡œ íˆ¬ì…
- 256 ì±„ë„ê³¼ ReLUë¡œ ì—®ì¸ ì´ 8ê°œì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼í•˜ê²Œ ëœë‹¤. í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” DeepSDF êµ¬ì¡°ë¥¼ ë”°ë¥´ê³ , skip connectionì„ 5ë²ˆì§¸ layerì˜ activationì—  íˆ¬ì…
- ì¶”ê°€ ë ˆì´ì–´ëŠ” volume densityÂ ë¥¼ outputìœ¼ë¡œ ì‚°ì¶œ
