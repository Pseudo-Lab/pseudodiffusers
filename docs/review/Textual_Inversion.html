

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Textual Inversion &#8212; Text-to-Image Generation-feat-Diffusion</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/review/Textual_Inversion';</script>
    <link rel="shortcut icon" href="../../_static/PseudoLab_logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Custom Diffusion" href="CustomDiffusion.html" />
    <link rel="prev" title="Latent Diffusion Model" href="Latent_Diffusion_Model.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/PseudoLab_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/PseudoLab_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to PseudoDiffusers!!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Preliminary Works</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vae.html">VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="gan.html">GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="DDPM.html">DDPM</a></li>




<li class="toctree-l1"><a class="reference internal" href="DDIM.html">DDIM</a></li>
<li class="toctree-l1"><a class="reference internal" href="A_Study_on_the_Evaluation_of_Generative_Models.html">A Study on the Evaluation of Generative Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Generation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="cycleGAN.html">CycleGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="StyleGAN.html">StyleGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffusion_beats_GANs.html">Diffusion Models Beat GANs on Image Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="dalle.html">DALL-E</a></li>
<li class="toctree-l1"><a class="reference internal" href="DALLE2.html">DALL-E 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="dreambooth.html">DreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="ControlNet.html">ControlNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="Latent_Diffusion_Model.html">Latent Diffusion Model</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Textual Inversion</a></li>








<li class="toctree-l1"><a class="reference internal" href="CustomDiffusion.html">Custom Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="LoRA.html">LoRA</a></li>









<li class="toctree-l1"><a class="reference internal" href="I-DDPM.html">I-DDPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="StyO.html">StyO</a></li>
<li class="toctree-l1"><a class="reference internal" href="imagen.html">Imagen</a></li>
<li class="toctree-l1"><a class="reference internal" href="imagen_editor.html">Imagen Editor</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDEdit.html">SDEdit</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDXL.html">SDXL</a></li>
<li class="toctree-l1"><a class="reference internal" href="t2i_adapter.html">T2I-Adapter</a></li>
<li class="toctree-l1"><a class="reference internal" href="HyperDreamBooth.html">HyperDreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="CM3leon.html">CM3leon</a></li>

<li class="toctree-l1"><a class="reference internal" href="Synthetic_Data_from_Diffusion_Models_Improves_ImageNet_Classification.html">Synthetic Data from Diffusion Models Improves ImageNet Classification</a></li>






<li class="toctree-l1"><a class="reference internal" href="GLIDE.html">GLIDE</a></li>
<li class="toctree-l1"><a class="reference internal" href="BBDM.html">BBDM</a></li>
<li class="toctree-l1"><a class="reference internal" href="Your_Diffusion_Model_is_Secretly_a_Zero_Shot_Classifier.html">Your Diffusion Model is Secretly a Zero-Shot Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="progressive_distillation.html">Progressive Distillation for Fast Sampling of Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ConceptLab.html">ConceptLab</a></li>
<li class="toctree-l1"><a class="reference internal" href="Diffusion_models_already_have_a_Semantic_Latent_Space.html">Diffusion Models already have a Semantic Latent Space</a></li>
<li class="toctree-l1"><a class="reference internal" href="Muse.html">Muse</a></li>


<li class="toctree-l1"><a class="reference internal" href="GIGAGAN.html">Scaling up GANs for Text-to-Image Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="consistency_models.html">Consistency Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="latent_consistency_models.html">Latent Consistency Models</a></li>

<li class="toctree-l1"><a class="reference internal" href="LLM_grounded_Diffusion.html">LLM Grounded Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="DiT.html">Abstract</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Video Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Make_A_Video.html">Make A Video</a></li>
<li class="toctree-l1"><a class="reference internal" href="VideoLDM.html">VideoLDM</a></li>
<li class="toctree-l1"><a class="reference internal" href="AnimateDiff.html">AnimateDiff</a></li>
<li class="toctree-l1"><a class="reference internal" href="Animate_Anyone.html">Animate Anyone</a></li>
<li class="toctree-l1"><a class="reference internal" href="DreaMoving.html">DreaMoving</a></li>
<li class="toctree-l1"><a class="reference internal" href="DreamPose.html">DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion</a></li>








</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">3D Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="NeRF.html">NeRF : Representing Scenes as Neural Radiance Fields for View Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="3DGS.html">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a></li>
<li class="toctree-l1"><a class="reference internal" href="DreamFusion.html"><strong>DreamFusion</strong></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Experiments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../experiments/js_exp.html">Synthetic Data with Stable Diffusion for Foliar Disease Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments/swjo_exp.html">Training DreamBooth on Naver Webtoon Face Dataset</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pseudo-lab/text-to-image-generation-feat-diffusion" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pseudo-lab/text-to-image-generation-feat-diffusion/issues/new?title=Issue%20on%20page%20%2Fdocs/review/Textual_Inversion.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/review/Textual_Inversion.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Textual Inversion</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Textual Inversion</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#related-work">Related work</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cf-gan-inversion">cf) GAN Inversion(이해 못함)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ldm-latent-diffusion-model">LDM(Latent Diffusion Model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-embeddings">Text Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Textual Inversion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">성능평가</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dall-e-2">DALL:E-2와 비교</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-guided-synthesis">Text guided synthesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pseudo-word">pseudo word 두 개 사용</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-reduction">Bias Reduction</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">정량평가</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setups">평가 setups</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">결과</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">주목할 점</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">사용자평가</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#limitation">Limitation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">마무리</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="admonition-information admonition">
<p class="admonition-title">Information</p>
<ul class="simple">
<li><p><strong>Title:</strong> An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion</p></li>
<li><p><strong>Reference</strong></p>
<ul>
<li><p>Paper:  <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a></p></li>
<li><p>Code: <a class="reference external" href="https://textual-inversion.github.io/">https://textual-inversion.github.io/</a></p></li>
<li><p>Review: <a class="reference external" href="https://devocean.sk.com/blog/techBoardDetail.do?page=&amp;query=&amp;ID=164320&amp;boardType=writer&amp;searchData=sam56903&amp;subIndex=&amp;idList=&amp;pnwriterID=sam56903">https://devocean.sk.com/blog/techBoardDetail.do?page=&amp;query=&amp;ID=164320&amp;boardType=writer&amp;searchData=sam56903&amp;subIndex=&amp;idList=&amp;pnwriterID=sam56903</a></p></li>
</ul>
</li>
<li><p><strong>Author:</strong> Kwang-Su Mun</p></li>
<li><p><strong>Last updated on May. 31. 2023</strong></p></li>
</ul>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="textual-inversion">
<h1>Textual Inversion<a class="headerlink" href="#textual-inversion" title="Permalink to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="abstract">
<h1>Abstract<a class="headerlink" href="#abstract" title="Permalink to this heading">#</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">이미지</span> <span class="mi">3</span><span class="o">-</span><span class="mi">5</span><span class="n">장으로</span> <span class="n">새로운</span> <span class="n">개념</span><span class="p">(</span><span class="n">또는</span> <span class="n">콘셉트</span><span class="p">,</span> <span class="n">concept</span><span class="p">)</span><span class="n">을</span> <span class="n">학습해</span> <span class="n">관련된</span> <span class="n">이미지를</span> <span class="n">뽑아내는</span> <span class="n">모델</span>
</pre></div>
</div>
<p>text-to-image model은 자연어를 통한 creation에 전례없는 자유도를 주었다. 하지만, 특정한 contept를 생성하고, 그것의 생김새를 바꾸거나, 새로운 역할이 주어지거나 참신한 장면이 그려지는건 아직 불분명하다. 즉, ‘이것을 그려줘’라고 말할 때, ‘이것’에 대한 설명을 prompt로 어떻게 할 것이냐는 물음에는 아직 한계가 있는 것 같다. 이를 해결하기 위해, 저자는 image를 3-5개만으로 사물이나 스타일과 같은 concept, 즉 새로운 ‘단어’를 고정된 text-to-image model의 embedding space에서 표현하는 방법을 제안한다. 이러한 ‘단어’는 자연어 문장에 녹아들어가, 직관적인 방법으로 ‘개인화된’ 이미지 생성을 이끌어 낸다. 특히, 독자적이면서 다양한 콘셉트를 capture하기 위해서는 single word embedding이 충분하다는 것을 알게 되었다.</p>
<figure class="align-default" id="textual-inverison-example">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbIVL03%2Fbtsg8b6ssL1%2FsZQKABrsLJG58fJuvqd5MK%2Fimg.png"><img alt="textual inverison example" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbIVL03%2Fbtsg8b6ssL1%2FsZQKABrsLJG58fJuvqd5MK%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 153 </span><span class="caption-text">textual inversion example \  (source: <a class="reference external" href="https://arxiv.org/abs/2208.01618">https://arxiv.org/abs/2208.01618</a>)</span><a class="headerlink" href="#textual-inverison-example" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h1>
<p>대규모 학습된 모델에 새로운 개념을 도입하는 일은 어려운 일이다. 각 새로운 개념에 대해 확장된 데이터 셋을 사용해 모델을 retraining하는 것은 엄청나게 비용이 많이 들고, 몇 가지 예제에 해서 fine-tuning은 보통 치명적인 망각을 초래한다. 따라서 저자들은 사전 훈련된 텍스트-이미지 모델의 텍스트 임베딩 공간에서 새로운 단어를 찾아 이러한 문제를 극복할 것을 제안.</p>
<figure class="align-default" id="architecture">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd0jLjp%2Fbtsg9DuSNQj%2FkjfhEfeTTA212mS5htrb71%2Fimg.png"><img alt="architecture" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd0jLjp%2Fbtsg9DuSNQj%2FkjfhEfeTTA212mS5htrb71%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 154 </span><span class="caption-text">architecture \  (source: <a class="reference external" href="https://arxiv.org/abs/2208.01618">https://arxiv.org/abs/2208.01618</a>)</span><a class="headerlink" href="#architecture" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>위 figure에서, “A photo of S*”은 tokenizer를 지나면서 각각 ‘508’, ‘701’, ‘73’, ‘*’과 같은 형태의 token set으로 변환되고, 이후 각 토큰은 자체 임베딩 벡터로 변환되고 이러한 벡터는 다운스트림 모델을 통해 제공됨.</p>
<p>input image의 concept를 나타내는, 새로운 pseudo-word인 S<em>를 이용해 새로운 embedding vector(v</em>)를 나타낸다. 이후 이 vector는 다른 단어와 같이 처리되며 생성 모델에 대한 새로운 text query를 구성하는데 사용될 수 있음. 따라서 이 query는 generator에 들어가서 사용자가 의도한바와 일치하도록 새로운 image를 생성하도록 하는 것이 전반적인 그림이라고 볼 수 있음.</p>
<p>여기서 중요한 것은, 이 과정에서 생성모델(여기서는 LDM이 쓰임)은 untouched되어 있다는 것(즉, 따로 수정이 들어가지 않는듯함). 그렇게 함으로써 새로운 task에 대한 fine-tuning을 할 때 일반적으로 손실되는 text에 대한 이해도나 generalization을 유지할 수 있음.</p>
<p>이러한 ‘유사단어’를 찾기 위해, 이 작업을 하나로 inversion시켜 프레임화 한다. 그리고 고정된, pre-trained text-to-image model을 사용하고, 3-5개의 concept를 나타내는 small image set이 주어진다. 저자들은 ‘a photo of S*’와 같은 형태의 문장을 설정해 주어진 작은 dataset에서 이미지를 재구성 하는 것으로 이어지는 single-word embedding을 찾는 것을 목표로 함.</p>
<p>이 모델의 목표는 <strong>새로운 concept인 입력 이미지를 나타내는 S*를 표현하는 방법을 찾는 것</strong>이며, 이러한 task를 **’textual inversion’**이라고 한다고 함.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>This embedding is found through an optimization process, which we refer to as “Textual Inversion”.
</pre></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="related-work">
<h1>Related work<a class="headerlink" href="#related-work" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>text-guided synthesis</p></li>
<li><p>GAN inversion</p></li>
<li><p>Diffusion-based inversion</p></li>
<li><p>personalization</p>
<ul>
<li><p>PALAVRA: image를 S*으로 바꾸는데 사용되는 기술로 추정.</p></li>
<li><p>pre-trained CLIP model을 이용해서 personalized object의 복구 및 segmentation을 수행. PALAVRA는 특정 개체를 참조하는 CLIP의 textual embedding space에서 pseudo-word를 식별함. 그 다음 검색을 위해 이미지를 설명하거나 어떤 장면에서 특정 개체를 분할하기 위해 사용됨. figure 5에서 보듯이, 그들의 접근 방식은 새로운 장면에서 그럴듯한 재구성 또는 합성에 필요한 세부 정보를 캡처하지 못함.</p></li>
</ul>
</li>
</ul>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="method">
<h1>Method<a class="headerlink" href="#method" title="Permalink to this heading">#</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Our</span> <span class="n">goal</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">enable</span> <span class="n">language</span><span class="o">-</span><span class="n">guided</span> <span class="n">generation</span> <span class="n">of</span> <span class="n">new</span><span class="p">,</span> <span class="n">user</span><span class="o">-</span><span class="n">specified</span> <span class="n">concepts</span><span class="o">.</span>
</pre></div>
</div>
<ul class="simple">
<li><p>의역) 목표: 유저가 의도한 것에 초첨을 맞춘, 새로운 concept를 embedding으로 잘 가이드해서 괜찮은 성과물을 내는 것.</p></li>
</ul>
<p>따라서 pre-trained text-to-image model의 중간 단계의 representation으로 이러한 새로운 ‘concepts’을 인코딩하는데 초점을 맞춤. 일반적인 text-to-image model에서는 image의 representation에 대한 후보군을 text encoder의 word-embedding 단계에서 찾는다. 그러나 이러한 접근 방식은 이미지에 대한 in-depth visual understanding을 필요로 하지 않는다(생성자가 이미지에 대해서 시각적인 이해? 없이 그린다.) 따라서 여기서는 GAN inversion에서 영감을 받은 visual reconstruction objective를 제시.</p>
<section id="cf-gan-inversion">
<h2>cf) GAN Inversion(이해 못함)<a class="headerlink" href="#cf-gan-inversion" title="Permalink to this heading">#</a></h2>
<p>출처) - <a class="reference external" href="https://hyoseok-personality.tistory.com/entry/GAN-Inversion">https://hyoseok-personality.tistory.com/entry/GAN-Inversion</a></p>
<figure class="align-default" id="gan-inversion">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpomZT%2Fbtsg9EHfVqc%2F4a4K6BmSPZV5ncVQXtfCHk%2Fimg.png"><img alt="GAN inversion" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpomZT%2Fbtsg9EHfVqc%2F4a4K6BmSPZV5ncVQXtfCHk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 155 </span><span class="caption-text">GAN inversion \  (source: <a class="reference external" href="https://hyoseok-personality.tistory.com/entry/GAN-Inversion">https://hyoseok-personality.tistory.com/entry/GAN-Inversion</a>)</span><a class="headerlink" href="#gan-inversion" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>입력 이미지와 유사한 결과 이미지를 얻을 수 있도록 하는 latent vector를 찾는 과정. GAN이 학습되면 random latent vector로부터 이미지를 생성해낸다. GAN inversion은 이의 역과정으로써 GAN의 latent space로 input image를 inverting시켜 latent vector를 알아가는 과정.</p></li>
</ul>
</section>
<section id="ldm-latent-diffusion-model">
<h2>LDM(Latent Diffusion Model)<a class="headerlink" href="#ldm-latent-diffusion-model" title="Permalink to this heading">#</a></h2>
<p>논문에서는 생성모델로서 LDM(Latent Diffusion Model)을 사용함. 이전에 말했듯이, LDM은 하나도 건들지 않음.</p>
<figure class="align-default" id="ldm-objective-function">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdw5kRl%2FbtshgoiBpt4%2Fz72rzU3tvL8kLFbtBXwWVk%2Fimg.png"><img alt="LDM objective function" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdw5kRl%2FbtshgoiBpt4%2Fz72rzU3tvL8kLFbtBXwWVk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 156 </span><span class="caption-text">LDM objective function \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#ldm-objective-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="text-embeddings">
<h2>Text Embeddings<a class="headerlink" href="#text-embeddings" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="text-embedding">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv0EWv%2Fbtsg9e9ZI4u%2FzfXraAXg1vpKpxemZLtVPk%2Fimg.png"><img alt="Text-Embedding" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fv0EWv%2Fbtsg9e9ZI4u%2FzfXraAXg1vpKpxemZLtVPk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 157 </span><span class="caption-text">Text-Embedding \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#text-embedding" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>입력된 문자열의 각 단어, 하위 단어는 tokenizer를 통과하며, 미리 정의된 dictionary에서 index token으로 변환함. 각 토큰을 통해 찾을 수 있는 고유한 임베딩 벡터에 연결됨.</p></li>
<li><p>index에 의한 embedding vector는 일반적으로 text encoder인 C_Θ의 일부로 학습된다. 이러한 space를 inversion target으로 삼았음. 새로운 개념을 나타내기 위해 자리표시자 문자열인 S<em>를 새롭게 지정함. 이 과정에서 PALAVRA를 사용했을 것으로 추정함. 임베딩 process에 개입해서 tokenize된 문자열과 관련된 vector를 새로운 학습된 embedding V</em>로 대체하여 본질적으로 어휘(pseudo-word)에 개념을 주입함. 이렇게 함으로써 다른 단어와 마찬가지로 concept를 포함하는 새로운 문장을 만들 수 있었음.</p></li>
</ul>
</section>
<section id="id1">
<h2>Textual Inversion<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>새로운 embedding을 찾기 위해 작은 규모의 dataset(3-5장)을 사용해 다양한 배경 또는 포즈와 같은 여러 설정에 걸쳐 목표 concept을 묘사함. 이러한 작은 dataset에서 LDM loss를 최소화하는 과정을 통해 V를 최적화함. 생성 조건을 고정하기 위해 CLIP ImageNet 템플릿에서 파생된 중립 컨텍스트 텍스트를 무작위로 샘플링한다. 여기에는 “A photo of S*”, “A rendition of S*” 등의 형식 프롬프트가 포함된다.(아마 원본 이미지와 최대한 비슷하게 만들어서 원본과 비교하기 위한 목적이 아닐까 싶음) 최적화 목표식은 다음과 같음.</p>
<figure class="align-default" id="textual-inversion-objective-function">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqY4nD%2FbtshiHP4k6T%2FvZrYjfSUAE2XePwon4rTIk%2Fimg.png"><img alt="textual inversion objective function" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqY4nD%2FbtshiHP4k6T%2FvZrYjfSUAE2XePwon4rTIk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 158 </span><span class="caption-text">textual inversion objective function \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#textual-inversion-objective-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>LDM loss함수와 매우 유사함. 여기서 CΘ와 eΘ는 고정. 해당 따라서 학습된 embedding이 개념에 미세한 시각적 detail을 포착할 수 있을것으로 기대함.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id2">
<h1>성능평가<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h1>
<section id="dall-e-2">
<h2>DALL:E-2와 비교<a class="headerlink" href="#dall-e-2" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="compare-with-dalle-2">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkJvkY%2Fbtsg95YTKmc%2FX6lxVI5tL30ZP5gKEmoAv1%2Fimg.png"><img alt="compare with DALLE-2" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkJvkY%2Fbtsg95YTKmc%2FX6lxVI5tL30ZP5gKEmoAv1%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 159 </span><span class="caption-text">compare with DALLE-2 \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#compare-with-dalle-2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>input image에 대한 디테일을 더 잘 포착하는 모습을 볼 수 있다.</p></li>
</ul>
</section>
<section id="text-guided-synthesis">
<h2>Text guided synthesis<a class="headerlink" href="#text-guided-synthesis" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="id3">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRLYR1%2Fbtsg95SasXe%2FaUe9K6FVb2yC9sZqoK5eSk%2Fimg.png"><img alt="text guided synthesis" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRLYR1%2Fbtsg95SasXe%2FaUe9K6FVb2yC9sZqoK5eSk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 160 </span><span class="caption-text">text guided synthesis - 입력 이미지의 스타일과 유사하면서도 text guide에 맞춰서 잘 진행함.
\  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Textual Inversion 모델은 새로운 주제에 대해 더 정확하게 개념을 보존하고, 새로운 임베딩과 나머지 캡션들에 대해서도 모두 추론이 가능했음.</p></li>
</ul>
<figure class="align-default" id="style-transfer">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLlXhf%2Fbtsg8cEna6l%2FgiZvyYgqCaPj6X5wKTIzZk%2Fimg.png"><img alt="style transfer" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLlXhf%2Fbtsg8cEna6l%2FgiZvyYgqCaPj6X5wKTIzZk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 161 </span><span class="caption-text">style transfer \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#style-transfer" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>적은 데이터셋으로도 style을 보존하면서 표현한 그림</p></li>
</ul>
</section>
<section id="pseudo-word">
<h2>pseudo word 두 개 사용<a class="headerlink" href="#pseudo-word" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="two-pseudo-word">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJtPJY%2Fbtsg9OinOOb%2FMLn4k48Hk7CP7vGv1yAaYk%2Fimg.png"><img alt="two pseudo word" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJtPJY%2Fbtsg9OinOOb%2FMLn4k48Hk7CP7vGv1yAaYk%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 162 </span><span class="caption-text">two pseudo word \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#two-pseudo-word" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="bias-reduction">
<h2>Bias Reduction<a class="headerlink" href="#bias-reduction" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="id4">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPakAR%2Fbtsg9OvWWW9%2FJZkKl1AFTKJgEKJsA2rb2K%2Fimg.png"><img alt="Bias reduction" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FPakAR%2Fbtsg9OvWWW9%2FJZkKl1AFTKJgEKJsA2rb2K%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 163 </span><span class="caption-text">Bias reduction \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>기존 모델의 결과를 보면, 위 사진에서와 같이 ‘의사’라는 단어를 사용하면, 보통 백인 남성 의사를 잘 그려냈음. 이는 기존 데이터셋에서 남성 의사 사진 데이터가 많았음을 보여준다. 보다 작은 imageset에서 새로운 embedding을 학습함으로써 이러한 bias를 줄일 수 있음을 보여준다(즉, 성별 및 인종적 다양성에 대한 인식을 높일 수 있음).</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id5">
<h1>정량평가<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h1>
<p>latent space embedding의 품질을 분석.</p>
<ol class="arabic simple">
<li><p>reconstruction(y축?):  target concept를 얼마나 잘 복제하는지. 특정 이미지가 아닌 개념에 대한 변형을 생성하므로 의미적 CLIP 공간 거리를 고려하여 유사성을 측정.(이미지에 자체가 아닌, 이미지가 가진 ‘개념’에 대해 latent space를 생성하므로)  각 컨셉에 대해 “A photo of S*”라는 prompt를 사용해 64개의 이미지를 생성.</p></li>
<li><p>editability(x축?): text prompt를 사용해 개념을 수정하는 능력을 평가. 다양한 난이도와 다양한 설정의 prompt를 사용해 일련의 이미지를 생성.</p></li>
</ol>
<p>각 prompt 별로, 50 DDIM step을 사용해 64개의 샘플을 만들고, CLIP-space embedding을 평가, textual prompt의 CLIP-space embedding에서 cosine similarity를 계산. 높은 스코어는 더 높은 editing capability와 prompt의 신뢰도를 보여줌.</p>
<section id="setups">
<h2>평가 setups<a class="headerlink" href="#setups" title="Permalink to this heading">#</a></h2>
<p>GAN inversion에서 영감을 받은 실험 환경 설정에 따름. 생략</p>
</section>
<section id="id6">
<h2>결과<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="quantative-evaluation1">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcxKm1h%2Fbtshb63SIYh%2FNflBiQZTV5V0yh0I3EYpq1%2Fimg.png"><img alt="quantative evaluation1" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcxKm1h%2Fbtshb63SIYh%2FNflBiQZTV5V0yh0I3EYpq1%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 164 </span><span class="caption-text">quantative evaluation1 \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#quantative-evaluation1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="id7">
<h3>주목할 점<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>많은 baseline과 우리 방법의 semantic reconstruction quality는 단순히 training set에서 임의의 이미지를 샘플링하는 것과 비슷함(== 원본 이미지와 생성된 이미지가 큰 차이가 없었다?)</p></li>
<li><p>single-word method는 비슷한 reconstruction quality를 달성하고, 모든 multi-word baseline에서 상당히 향상된 editablity을 달성. 이러한 점은 text embedding space의 인상적인 유연성을 나타내고, 단일 pseudo word만 사용하면서 높은 정확도로 새로운 개념을 캡처하는데 도움이 될 수 있음을 보여줌.</p></li>
<li><p>baseline이 distortion-editability tradeoff 곡선의 outline을 그리며 실제 단어 분포에 더 가까운 embedding이 더 쉽게 수정될 수 있음. 그러나 target의 세부 정보를 캡처하지는 못함. 반대로, 단어 분포에서 멀리 벗어나면 editability가 크게 감소하는 대신 향상된 reconstruction이 가능해짐. 특히 single embedding model은 단순히 learning rate를 변경해 이 곡선을 따라 이동할 수 있으므로 사용자에게 이 tradeoff에 대한 어느 정도의 제어를 제공함.</p></li>
<li><p>concept에 대한 human description을 사용하면 유사성을 포착하지 못하면서도, editability가 감소함.</p></li>
</ol>
</section>
</section>
<section id="id8">
<h2>사용자평가<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="human-test">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frx5Ei%2Fbtsg9MSpakC%2FFsPkgODR3zTGIBnvq6RXik%2Fimg.png"><img alt="human test" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Frx5Ei%2Fbtsg9MSpakC%2FFsPkgODR3zTGIBnvq6RXik%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 165 </span><span class="caption-text">human test \  (source: <a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a>)</span><a class="headerlink" href="#human-test" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>두 개의 설문지:</p>
<ol class="arabic simple">
<li><p>사용자는 concept의 training set에서 4개의 이미지를 제공받았고, 이미지와의 유사성에 따라 5개의 모델에서 생성된 결과의 순위를 매김.</p></li>
<li><p>이미지 context를 설명하는 텍스트를 제공받았고, 텍스트와 생성된 이미지의 유사성에 따라 순위를 매김.</p></li>
</ol>
<p>각 질문별로 600개씩 총 1,200개의 응답을 수집.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="limitation">
<h1>Limitation<a class="headerlink" href="#limitation" title="Permalink to this heading">#</a></h1>
<ol class="arabic simple">
<li><p>이미지 생성에 더 많은 자유도를 제공하지만, concept의 의미론적인 본질을 파악하거나, 정확한 shape를 학습하는데 한계.</p></li>
<li><p>최적화가 오래 걸린다. 하나의 concept를 학습하는데 약 2시간이 소요됨.</p></li>
</ol>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id9">
<h1>마무리<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h1>
<p>: 새로운 설정과 장면에서 특정 concept의 이미지를 생성하기 위해 text-to-image model를 활용하는 개인화되며, language-guided generation을 소개함. 여기서 사용한 ‘text inversion’은 pretrained text-to-image 모델의 text embedding space 내에서 concept를 새로운 pseudo word로 inverse하여 작동함. 이러한 pseudo-word는 간단한 자연어 설명을 사용해 새로운 장면에 삽입할 수 있으므로 간단하고 직관적인 수정이 가능함.</p>
<p>어떤 의미에서 이 방법은 사용자가 편집하기 쉽도록 텍스트 기반 interpace를 사용하지만 자연 언어의 한계에 접근할 때 시각적 단서를 제공하는 등 multi modal 정보를 활용할 수 있도록 함.</p>
<p>이러한 접근 방식은 공개적으로 사용가능한 가장 큰 text-to-image model인 LDM을 통해 구현됨. 그러나 접근 방식에 아키텍처 세부 정보에 의존하지 않음. 따라서 textual inversion은 추가적인 대규모 text-to-image model에 쉽게 적용할 수 있다고 생각. 거기에서 text-to-image alignment, shape preseravation, image generation fidelity가 더 향상될 수 있음.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs\review"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Latent_Diffusion_Model.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Latent Diffusion Model</p>
      </div>
    </a>
    <a class="right-next"
       href="CustomDiffusion.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Custom Diffusion</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Textual Inversion</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#related-work">Related work</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cf-gan-inversion">cf) GAN Inversion(이해 못함)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ldm-latent-diffusion-model">LDM(Latent Diffusion Model)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-embeddings">Text Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Textual Inversion</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">성능평가</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dall-e-2">DALL:E-2와 비교</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-guided-synthesis">Text guided synthesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pseudo-word">pseudo word 두 개 사용</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-reduction">Bias Reduction</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">정량평가</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setups">평가 setups</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">결과</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">주목할 점</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">사용자평가</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#limitation">Limitation</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">마무리</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By PseudoLab
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>