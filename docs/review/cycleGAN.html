

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>CycleGAN &#8212; Text-to-Image Generation-feat-Diffusion</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/review/cycleGAN';</script>
    <link rel="shortcut icon" href="../../_static/PseudoLab_logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="StyleGAN" href="StyleGAN.html" />
    <link rel="prev" title="A Study on the Evaluation of Generative Models" href="A_Study_on_the_Evaluation_of_Generative_Models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/PseudoLab_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/PseudoLab_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome to PseudoDiffusers!!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Preliminary Works</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vae.html">VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="gan.html">GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="DDPM.html">DDPM</a></li>




<li class="toctree-l1"><a class="reference internal" href="DDIM.html">DDIM</a></li>
<li class="toctree-l1"><a class="reference internal" href="A_Study_on_the_Evaluation_of_Generative_Models.html">A Study on the Evaluation of Generative Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Generation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">CycleGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="StyleGAN.html">StyleGAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="diffusion_beats_GANs.html">Diffusion Models Beat GANs on Image Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="dalle.html">DALL-E</a></li>
<li class="toctree-l1"><a class="reference internal" href="DALLE2.html">DALL-E 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="dreambooth.html">DreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="ControlNet.html">ControlNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="Latent_Diffusion_Model.html">Latent Diffusion Model</a></li>

<li class="toctree-l1"><a class="reference internal" href="Textual_Inversion.html">Textual Inversion</a></li>








<li class="toctree-l1"><a class="reference internal" href="CustomDiffusion.html">Custom Diffusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="LoRA.html">LoRA</a></li>









<li class="toctree-l1"><a class="reference internal" href="I-DDPM.html">I-DDPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="StyO.html">StyO</a></li>
<li class="toctree-l1"><a class="reference internal" href="imagen.html">Imagen</a></li>
<li class="toctree-l1"><a class="reference internal" href="imagen_editor.html">Imagen Editor</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDEdit.html">SDEdit</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDXL.html">SDXL</a></li>
<li class="toctree-l1"><a class="reference internal" href="t2i_adapter.html">T2I-Adapter</a></li>
<li class="toctree-l1"><a class="reference internal" href="HyperDreamBooth.html">HyperDreamBooth</a></li>
<li class="toctree-l1"><a class="reference internal" href="CM3leon.html">CM3leon</a></li>

<li class="toctree-l1"><a class="reference internal" href="Synthetic_Data_from_Diffusion_Models_Improves_ImageNet_Classification.html">Synthetic Data from Diffusion Models Improves ImageNet Classification</a></li>






<li class="toctree-l1"><a class="reference internal" href="GLIDE.html">GLIDE</a></li>
<li class="toctree-l1"><a class="reference internal" href="BBDM.html">BBDM</a></li>
<li class="toctree-l1"><a class="reference internal" href="Your_Diffusion_Model_is_Secretly_a_Zero_Shot_Classifier.html">Your Diffusion Model is Secretly a Zero-Shot Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="progressive_distillation.html">Progressive Distillation for Fast Sampling of Diffusion Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ConceptLab.html">ConceptLab</a></li>
<li class="toctree-l1"><a class="reference internal" href="Diffusion_models_already_have_a_Semantic_Latent_Space.html">Diffusion Models already have a Semantic Latent Space</a></li>
<li class="toctree-l1"><a class="reference internal" href="Muse.html">Muse</a></li>


<li class="toctree-l1"><a class="reference internal" href="GIGAGAN.html">Scaling up GANs for Text-to-Image Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="consistency_models.html">Consistency Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="latent_consistency_models.html">Latent Consistency Models</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Video Generation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Make_A_Video.html">Make A Video</a></li>
<li class="toctree-l1"><a class="reference internal" href="VideoLDM.html">VideoLDM</a></li>
<li class="toctree-l1"><a class="reference internal" href="Animate_Anyone.html">Animate Anyone</a></li>
<li class="toctree-l1"><a class="reference internal" href="DreaMoving.html">DreaMoving</a></li>
<li class="toctree-l1"><a class="reference internal" href="DreamPose.html">DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion</a></li>








</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Experiments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../experiments/js_exp.html">Synthetic Data with Stable Diffusion for Foliar Disease Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments/swjo_exp.html">Training DreamBooth on Naver Webtoon Face Dataset</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pseudo-lab/text-to-image-generation-feat-diffusion" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pseudo-lab/text-to-image-generation-feat-diffusion/issues/new?title=Issue%20on%20page%20%2Fdocs/review/cycleGAN.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/docs/review/cycleGAN.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>CycleGAN</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#related-work">Related work</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-to-image-translation">Image-to-Image Translation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mode-collapse">Mode Collapse</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adversarial-loss">Adversarial Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cycle-consistency-loss">Cycle Consistency Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-objective">Full Objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network-architecture">Network Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-details">Training details</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#least-square-loss">(참고) least-square loss 추가 설명</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-against-baselines">Comparison against baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ablation-study-analysis-of-the-loss-function">Ablation Study - Analysis of the loss function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-reconstruction-quality">Image reconstruction quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-results-on-paired-datasets">Additional results on paired datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-discusssion">Limitations and Discusssion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="admonition-information admonition">
<p class="admonition-title">Information</p>
<ul class="simple">
<li><p><strong>Title:</strong> Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (ICCV 2017)</p></li>
<li><p><strong>Reference</strong></p>
<ul>
<li><p>Paper: <a class="reference external" href="https://arxiv.org/abs/1703.10593">https://arxiv.org/abs/1703.10593</a></p></li>
<li><p>Code: <a class="reference external" href="https://www.tensorflow.org/tutorials/generative/cyclegan?hl=ko">TensorFlow CycleGAN tutorial</a></p></li>
<li><p><a class="reference external" href="https://velog.io/&#64;sjinu/CycleGAN">[논문리뷰] Cycle GAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a>
<a class="reference external" href="https://comlini8-8.tistory.com/9">CycleGAN을 만든 사람이 한국인이라고? CycleGAN 논문 뜯어보기</a></p></li>
</ul>
</li>
<li><p><strong>Author:</strong> KwangSu Mun</p></li>
<li><p><strong>Author:</strong> ChangHwan Lee</p></li>
<li><p><strong>Last updated on May. 16, 2024</strong></p></li>
</ul>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="cyclegan">
<h1>CycleGAN<a class="headerlink" href="#cyclegan" title="Permalink to this heading">#</a></h1>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Image-to-image translation 은 한 이미지 도메인을 다른 이미지 도메인으로 변환시키는 computer vision 의 한 task 입니다.</p></li>
<li><p>Image-to-image translation 은 보통 input과 output이 짝이 지어진 상태에서 학습하지만 짝이 지어진 학습 데이터를 얻는 것이 어렵습니다. 따라서 CycleGAN 논문에서는 짝지어진 예시 없이 <span class="math notranslate nohighlight">\(X\)</span> 라는 domain 으로부터 얻은 이미지를 target domain <span class="math notranslate nohighlight">\(Y\)</span> 로 바꾸는 방법을 제안합니다. 이 연구는 Adversarial loss 를 활용해, <span class="math notranslate nohighlight">\(G(x)\)</span> 로부터 생성된 이미지 데이터의 분포와 <span class="math notranslate nohighlight">\(Y\)</span> 로부터의 이미지 데이터의 분포가 구분이 불가능하도록 함수 <span class="math notranslate nohighlight">\(G: X -&gt; Y\)</span> 를 학습시키는 것을 목표로 합니다. 더불어, <span class="math notranslate nohighlight">\(X -&gt; Y\)</span> 로의 mapping 에 제약을 가해서 원하는 이미지를 강제하기 위해 <span class="math notranslate nohighlight">\(F: Y -&gt; X\)</span> 와 같은 역방향 매핑을 함께 진행합니다. 즉, <span class="math notranslate nohighlight">\(F(G(x))\)</span> 가 <span class="math notranslate nohighlight">\(X\)</span> 와 유사해지도록 강제하는 cycle consistency loss 를 도입했습니다.</p></li>
<li><p>결과적으로 collection style transfer, object transfiguration, season transfer, photo enhancement 등의 task 에서 이미지 pair 가 존재하지 않는 상태에서 우수한 결과를 보여줬다고 합니다.</p></li>
</ul>
</section>
<section id="related-work">
<h2>Related work<a class="headerlink" href="#related-work" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>GAN : adversarial loss 를 사용하여 이미지를 생성하는 방법입니다.</p></li>
<li><p>Image-to-Image Translation : 특정 image 를 input 로 넣으면 그에 맞는 image 가 output 로 나오는 방법입니다. pix2pix 같은 방법이 있으며 상세한 설명은 아래의 Background section 을 참조하면 됩니다.</p></li>
<li><p>Unpaired Image-to-Image Translation : 위의 Image-to-Image Translation 에서 pair 가 아닌 데이터로 학습해서 Image-to-Image Translation 과 같은 input, output 결과가 나오도록 만드는 방법입니다.</p></li>
<li><p>Cycle Consistency : 한 이미지를 다른 도메인으로 변환하고 다시 원래 도메인으로 변환할 때 처음의 원본으로 되도록 하여 일종의 순환(사이클)을 만드는 방법으로 학습 프로세스가 더 안정적이게 되고, 이미지 간의 일관성을 보다 잘 유지할 수 있도록 만듭니다. (ex) <span class="math notranslate nohighlight">\(X\)</span> 를 모델 <span class="math notranslate nohighlight">\(A\)</span> 에 거쳐 <span class="math notranslate nohighlight">\(Y\)</span> 로 만든 뒤 다시 모델 <span class="math notranslate nohighlight">\(B\)</span> 를 거쳐 <span class="math notranslate nohighlight">\(X\)</span> 로 복구)</p></li>
<li><p>Neural Style Transfer : pre-trained 된 deep features 의 Gram matrix statistics 일치를 기반으로 이미지 content 를 다른 image 의 스타일과 결합하여 새로운 이미지를 합성하는 방법입니다.</p></li>
</ul>
</section>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this heading">#</a></h2>
<section id="image-to-image-translation">
<h3>Image-to-Image Translation<a class="headerlink" href="#image-to-image-translation" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id1">
<a class="bg-primary mb-1 reference internal image-reference" href="https://phillipi.github.io/pix2pix/images/teaser_v3.png"><img alt="https://phillipi.github.io/pix2pix/images/teaser_v3.png" class="bg-primary mb-1" src="https://phillipi.github.io/pix2pix/images/teaser_v3.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 44 </span><span class="caption-text">image-to-image translation</span><a class="headerlink" href="#id1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Image-to-image translation 은 input image 를 다른 스타일, 속성, 구조 등을 가진 output image 로 변환하는 task 입니다. 예를 들어 사진을 그림으로 변환한다거나, 낮에 찍은 사진을 밤에 찍은 것 처럼 변환하는 것을 말합니다. 흔히 translation 은 input 과 output 로 짝이 지어진 데이터를 바탕으로 학습이 이루어져 있었는데요. 짝이 지어진 사진 데이터를 얻는 것은 어렵고 값이 비싼 일이 됩니다.</p>
<figure class="align-default" id="id2">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhMGUZ%2Fbtr7HimHXN5%2FHvjTh02iCzP5Sgk8UYkKO0%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhMGUZ%2Fbtr7HimHXN5%2FHvjTh02iCzP5Sgk8UYkKO0%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhMGUZ%2Fbtr7HimHXN5%2FHvjTh02iCzP5Sgk8UYkKO0%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 45 </span><span class="caption-text">paired and unpaired data</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>이 논문에서는 input image와 output image가 일대일로 짝지어지지 않은 상태에서 하나의 image 모음의 특성을 캡쳐하고, 이러한 특성을 다른 image 모음으로 변환할 수 있는 방법을 제시합니다.
GAN은 domain <span class="math notranslate nohighlight">\(X\)</span> 에 이미지 한 세트, domain <span class="math notranslate nohighlight">\(Y\)</span> 에 이미지 한 세트가 제공되고, model 의 output 과 <span class="math notranslate nohighlight">\(Y\)</span> 가 discriminator 에 의해 구별할 수 없도록 모델 <span class="math notranslate nohighlight">\(G: X -&gt; Y\)</span> 를 학습합니다. 하지만, 이것이 개별 입력 <span class="math notranslate nohighlight">\(x\)</span> 와 출력 <span class="math notranslate nohighlight">\(y\)</span> 가 무조건 유의미하게 쌍을 이룬다는 것을 뜻하지는 않습니다. <span class="math notranslate nohighlight">\(G\)</span> 가 생성할 수 있는 image 에는 무한한 경우의 수가 있기 때문에 종종 mode collapse 현상이 일어나기도 합니다.</p>
</section>
<section id="mode-collapse">
<h3>Mode Collapse<a class="headerlink" href="#mode-collapse" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id3">
<a class="bg-primary mb-1 reference internal image-reference" href="https://1.bp.blogspot.com/-oDCR5UnEIl4/WZkIId-rYCI/AAAAAAAAAJk/PoLvou4JLNIxn5U-OmPFZ_heyxVQGbMNQCEwYBhgL/s1600/14.png"><img alt="https://1.bp.blogspot.com/-oDCR5UnEIl4/WZkIId-rYCI/AAAAAAAAAJk/PoLvou4JLNIxn5U-OmPFZ_heyxVQGbMNQCEwYBhgL/s1600/14.png" class="bg-primary mb-1" src="https://1.bp.blogspot.com/-oDCR5UnEIl4/WZkIId-rYCI/AAAAAAAAAJk/PoLvou4JLNIxn5U-OmPFZ_heyxVQGbMNQCEwYBhgL/s1600/14.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 46 </span><span class="caption-text">mode collapsing 출처: <a class="reference external" href="http://dl-ai.blogspot.com/2017/08/gan-problems.html">http://dl-ai.blogspot.com/2017/08/gan-problems.html</a></span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>어떤 input image 든 모두 같은 output image 로 매핑하면서 최적화에 실패하는 현상입니다. 이 현상은 generator 입장에서, discriminator 가 이 사진이 진짜 <span class="math notranslate nohighlight">\(Y\)</span>인지 가짜인 <span class="math notranslate nohighlight">\(\hat{Y}\)</span>인지 구별하는 것을 ‘<strong>속이기만</strong>’ 하면 되기 때문에 우리의 목적과 전혀 상관이 없는 데이터를 generator 가 만들더라도 문제가 생기지 않아서 발생합니다.</p>
<ul class="simple">
<li><p>참고: <a class="reference external" href="http://dl-ai.blogspot.com/2017/08/gan-problems.html">http://dl-ai.blogspot.com/2017/08/gan-problems.html</a></p></li>
</ul>
<p>이러한 이슈로 인해 추가 objective function 이 필요해졌습니다. 따라서 translation task 는 영어 -&gt; 프랑스어 -&gt; 영어로 번역했을 때 원래 문장에 다시 도달하는 것처럼, <span class="math notranslate nohighlight">\(X --&gt; Y --&gt; X'\)</span> 로 돌아가는 과정에서 <span class="math notranslate nohighlight">\(X\)</span> 와 <span class="math notranslate nohighlight">\(X'\)</span> 이 최대한 같아야 한다는 의미의 cycle consistency 이라는 속성을 이용합니다. 필요한 목적식을 간단하게 정리하면 다음과 같습니다.</p>
<ul class="simple">
<li><p>정방향, 역방향 adversarial loss: <span class="math notranslate nohighlight">\(X -&gt; Y &amp; Y -&gt; X\)</span></p></li>
<li><p>Cycle consistency loss: <span class="math notranslate nohighlight">\(X \)</span>\approx<span class="math notranslate nohighlight">\( F(G(x))\)</span></p></li>
</ul>
</section>
</section>
<section id="method">
<h2>Method<a class="headerlink" href="#method" title="Permalink to this heading">#</a></h2>
<!---->
<!--Overview 에서 전체적인 구성과 학습과정을 설명하며, 아래 "Adversarial Loss", "Cycle consistency Loss"는 모델의 핵심 요소임. 이를 기반으로 "full objective"가 나옴-->
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id4">
<a class="bg-primary mb-1 reference internal image-reference" href="../../_images/fig2.png"><img alt="../../_images/fig2.png" class="bg-primary mb-1" src="../../_images/fig2.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 47 </span><span class="caption-text">CycleGAN 도식화 자료</span><a class="headerlink" href="#id4" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>목표: <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> 를 mapping 하는 function 을 학습하는 것</p></li>
<li><p>용어 정리</p>
<ul>
<li><p>data 분포를 <span class="math notranslate nohighlight">\(x ~ p_{data}(x)\)</span>, <span class="math notranslate nohighlight">\(y ~ p_{data}(y)\)</span> 로 표기</p></li>
<li><p><span class="math notranslate nohighlight">\(G : X -&gt; Y\)</span>, <span class="math notranslate nohighlight">\(F: Y -&gt; X\)</span> 는 generator</p></li>
<li><p><span class="math notranslate nohighlight">\(D_X\)</span>, <span class="math notranslate nohighlight">\(D_Y\)</span> 는 discriminator</p></li>
<li><p><span class="math notranslate nohighlight">\(D_X\)</span> 는 <span class="math notranslate nohighlight">\(X\)</span> 와 <span class="math notranslate nohighlight">\(F(y)\)</span> 그리고 <span class="math notranslate nohighlight">\(D_Y\)</span> 는 <span class="math notranslate nohighlight">\(y\)</span> 와 <span class="math notranslate nohighlight">\(G(x)\)</span> 를 구분하고, 다음과 같이 두 개의 목적식으로 학습합니다.</p>
<ul>
<li><p>adversarial loss: 생성된 이미지의 분포를 대상 domain 의 data distribution 과 일치시키기 위한 것.</p></li>
<li><p>cycle consistency loss: 학습된 mapping <span class="math notranslate nohighlight">\(G\)</span> 와 <span class="math notranslate nohighlight">\(F\)</span> 가 서로 모순되는 것을 방지하기 위한 것.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="adversarial-loss">
<h3>Adversarial Loss<a class="headerlink" href="#adversarial-loss" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(G: X -&gt; Y\)</span> 와 <span class="math notranslate nohighlight">\(D_Y\)</span> 에 대한 목적식은 다음과 같습니다.</p>
<figure class="align-default" id="mathcal-l-gan-loss-function">
<img alt="L_GAN Loss function" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnvzuE%2Fbtr725OfuJy%2FI1IgwK5PIzXpzINWnJxysK%2Fimg.png" />
<figcaption>
<p><span class="caption-number">Fig. 48 </span><span class="caption-text"><span class="math notranslate nohighlight">\(\mathcal{L}_{GAN}\)</span> Loss function (source: <a class="reference external" href="https://arxiv.org/abs/1703.10593">https://arxiv.org/abs/1703.10593</a>)</span><a class="headerlink" href="#mathcal-l-gan-loss-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>이는 GAN 에서 쓰이는 loss function 를 사용하지만, 차이점이 있다면 <span class="math notranslate nohighlight">\(X -&gt; Y\)</span> 로 갈 때와 <span class="math notranslate nohighlight">\(Y -&gt; X\)</span> 로 갈 때 총 두 개의 수식이 나옵니다. 다시 말해, <span class="math notranslate nohighlight">\(F: Y -&gt; X\)</span> 와 <span class="math notranslate nohighlight">\(D_X\)</span> 에 대해서도 <span class="math notranslate nohighlight">\(F\)</span>, <span class="math notranslate nohighlight">\(D_X\)</span> 를 넣은 동일한 수식을 사용합니다.</p>
</section>
<section id="cycle-consistency-loss">
<h3>Cycle Consistency Loss<a class="headerlink" href="#cycle-consistency-loss" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id5">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fmq8pC%2Fbtr724Pl3Q2%2FUSK4TDRaUK860iIdvG0vV0%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fmq8pC%2Fbtr724Pl3Q2%2FUSK4TDRaUK860iIdvG0vV0%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fmq8pC%2Fbtr724Pl3Q2%2FUSK4TDRaUK860iIdvG0vV0%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 49 </span><span class="caption-text">cycle consistency loss function</span><a class="headerlink" href="#id5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>앞서 말했듯이, mapping distribution 에 제한을 두어 최대한 우리가 원하는 이미지를 생성하기 위해 사용되는 loss function 입니다.</p></li>
<li><p>예비 실험에서 L1 norm 을 adversarial loss 로 대체해봤는데, 성능 향상을 관찰할 수 없었다고 합니다.</p></li>
<li><p>cycle consistency loss 를 통해 유도된 결과는 아래 그림에서 볼 수 있습니다.</p></li>
</ul>
<figure class="align-default" id="id6">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzsgD6%2Fbtr8ay8PEBE%2F3mAKd1YSAiCK4ZXeIg84s1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzsgD6%2Fbtr8ay8PEBE%2F3mAKd1YSAiCK4ZXeIg84s1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzsgD6%2Fbtr8ay8PEBE%2F3mAKd1YSAiCK4ZXeIg84s1%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 50 </span><span class="caption-text">cycle consistency loss result</span><a class="headerlink" href="#id6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="full-objective">
<h3>Full Objective<a class="headerlink" href="#full-objective" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id7">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUyaOu%2Fbtr724Pl3Rj%2FigjKaeukv5m8Cbdzulp5jK%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUyaOu%2Fbtr724Pl3Rj%2FigjKaeukv5m8Cbdzulp5jK%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FUyaOu%2Fbtr724Pl3Rj%2FigjKaeukv5m8Cbdzulp5jK%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 51 </span><span class="caption-text">full objective function</span><a class="headerlink" href="#id7" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>이때 consistency loss 앞에 붙은 가중치 <span class="math notranslate nohighlight">\(\lambda\)</span> 는 GAN Loss 와의 상대적 중요도에 따라 결정됩니다.</p>
</section>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading">#</a></h2>
<section id="network-architecture">
<h3>Network Architecture<a class="headerlink" href="#network-architecture" title="Permalink to this heading">#</a></h3>
<p>Baseline architecture 로서 neural style transfer 와 super-resolution 에 인상적인 결과를 보여준 논문(<a class="reference external" href="https://arxiv.org/abs/1603.08155">https://arxiv.org/abs/1603.08155</a>) 에서 사용된 구조를 채택합니다.</p>
<ul class="simple">
<li><p>3 개의 convolutions and several residual blocks,</p></li>
<li><p>fractionally-strided convolution with stride 1/2,</p></li>
<li><p>feature 를 RGB 로 매핑하는 one convolution layer.</p></li>
<li><p>6 blocks for 128 x 128 image // 9 blocks for 256 x 256 및 고해상도 학습 image.</p></li>
<li><p>instance normalization</p></li>
</ul>
</section>
<section id="training-details">
<h3>Training details<a class="headerlink" href="#training-details" title="Permalink to this heading">#</a></h3>
<p>모델 학습을 안정화시키기 위해 아래와 같은 테크닉을 추가로 적용합니다.</p>
<ul class="simple">
<li><p>Loss function <span class="math notranslate nohighlight">\(\mathcal{L}_{GAN}\)</span> 에서 nll loss 를 least-squared loss 로 변경</p></li>
<li><p>생성된 이미지 중 가장 최근의 50개를 따로 저장해 discriminator 가 이를 한꺼번에 분류(모델 진동을 최소화하기 위함)</p></li>
</ul>
</section>
<section id="least-square-loss">
<h3>(참고) least-square loss 추가 설명<a class="headerlink" href="#least-square-loss" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://velog.io/&#64;sjinu/CycleGAN">https://velog.io/&#64;sjinu/CycleGAN</a>
-<a class="reference external" href="https://ysbsb.github.io/gan/2022/02/23/LSGAN.html">https://ysbsb.github.io/gan/2022/02/23/LSGAN.html</a></p></li>
</ul>
<p>LSGAN 을 참고했으며, 논문에서는 generator 업데이트시 더 안정적인 학습과 quality 높은 결과를 생성한다고 합니다.</p>
<figure class="align-default" id="id8">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F6JIT8%2Fbtr73nVyIqs%2FKfcPK33U3OY0AjKhjFlUh1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F6JIT8%2Fbtr73nVyIqs%2FKfcPK33U3OY0AjKhjFlUh1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F6JIT8%2Fbtr73nVyIqs%2FKfcPK33U3OY0AjKhjFlUh1%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 52 </span><span class="caption-text">출처: <a class="reference external" href="https://velog.io/&#64;sjinu/CycleGAN">https://velog.io/&#64;sjinu/CycleGAN</a></span><a class="headerlink" href="#id8" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>(원래 Discriminator 는 이보다 더 고차원이지만) 간략히 2차원을 표방하면 결정경계를 위와 같이 나타낼 수 있습니다. 윗 쪽이 가짜 영역, 아래 쪽이 진짜 영역입니다 이 때, 아래에 보면 진짜 데이터 샘플과 거리가 먼 가짜 데이터 샘플이 존재합니다. 즉, NLL Loss 를 사용한다면, Generator 의 입장에서는 이미 Discriminator 를 잘 속이고 있기 때문에 학습할 필요가 없게 됩니다. 즉, Vanishing Gradient 현상이 일어나기 때문에, Discriminator 를 잘 속인다는 이유만으로, 안 좋은 샘플을 생성하는 것에 대해 패널티를 줄 수가 없게 됩니다. 이 때, LSGAN 을 사용한다면 실제 데이터 분포와 가짜 데이터 샘플이 거리가 먼 것에 대해서도 패널티를 주게 됩니다.</p>
<figure class="align-default" id="id9">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHsUiX%2Fbtr77PQw99h%2F0Er06IYIGYlBGw2rVufXc0%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHsUiX%2Fbtr77PQw99h%2F0Er06IYIGYlBGw2rVufXc0%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FHsUiX%2Fbtr77PQw99h%2F0Er06IYIGYlBGw2rVufXc0%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 53 </span><span class="caption-text">출처: <a class="reference external" href="https://velog.io/&#64;sjinu/CycleGAN">https://velog.io/&#64;sjinu/CycleGAN</a></span><a class="headerlink" href="#id9" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>그리고 모든 실험에 대해서 <span class="math notranslate nohighlight">\(\lambda\)</span> 를 10 으로 설정하고, batch size = 1, 그리고 Adam solver 를 사용했습니다. 첫 100 epoch 동안에는 learning rate 를 0.0002 로 설정했고, 다음 100 epoch 마다 0 으로 조금식 수렴하게 scheduling 하였습니다.</p>
</section>
</section>
<section id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this heading">#</a></h2>
<p>모델 성능 평가를 위해 아래와 같은 세 개의 지표를 기반으로 기존의 CoGAN, SimGAN, pix2pix baseline 모델과 비교했습니다. 그 외 loss function 에 대한 ablation study 도 수행했습니다.</p>
<ol class="arabic simple">
<li><p>AMT perceptual studies: 참가자들은 실제 사진이미지 vs 가짜 이미지, 또는 지도 이미지 vs 가짜이미지에 노출된 후 진짜라고 생각되는 이미지를 선택하게 합니다.</p></li>
<li><p>FCN Score: 1번 study 가 테스트에 있어 매우 좋은 기준임에도 불구하고, 이번에는 사람을 대상으로 한 실험이 아닌 양적인 기준을 사용합니다. 우선적으로 FCN 모델을 통해 생성된 사진에 대한 레이블 맵을 예측합니다. 이 레이블 맵은 아래에서 설명하는 standard semantic segmentation metric 을 사용하여 input ground truth label 과 비교할 수 있습니다. “도로 상의 자동차”라는 label 에서 사진 이미지를 생성하면, 생성된 이미지에 적용된 FCN 이 “도로 상의 자동차”를 감지하면 성공한 것입니다.</p></li>
<li><p>Semantic segmentation metric: pixel 당 정확도, class 당 정확도, 그리고 IoU(Intersection-Over-Union) 를 포함하는 cityscapes benchmark 의 표준 metric 를 사용합니다.</p></li>
</ol>
<section id="comparison-against-baselines">
<h3>Comparison against baselines<a class="headerlink" href="#comparison-against-baselines" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id10">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcZUe4E%2Fbtr8eXUQ6ou%2FikWglP8dEglGUny4dRkMjK%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcZUe4E%2Fbtr8eXUQ6ou%2FikWglP8dEglGUny4dRkMjK%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcZUe4E%2Fbtr8eXUQ6ou%2FikWglP8dEglGUny4dRkMjK%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 54 </span><span class="caption-text">Comparison aginst baselines</span><a class="headerlink" href="#id10" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>타 baseline 모델보다 성능이 좋을 뿐만 아니라, fully supervised 모델인 pix2pix 와 비슷한 품질의 translation 성능을 보여줍니다.</p>
<ul class="simple">
<li><p>AMT Score *</p></li>
</ul>
<figure class="align-default" id="id11">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1Zhnx%2Fbtr8eWhk9ID%2FtauuT1N0W2qxRekj3IAnc1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1Zhnx%2Fbtr8eWhk9ID%2FtauuT1N0W2qxRekj3IAnc1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1Zhnx%2Fbtr8eWhk9ID%2FtauuT1N0W2qxRekj3IAnc1%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 55 </span><span class="caption-text">AMT score</span><a class="headerlink" href="#id11" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Table 1 은 AMT perceptual realism task 에 대한 성능을 나타냅니다. CycleGAN 의 지도에서 항공 사진, 그리고 항공 사진에서 지도 translation 결과에서 약 1/4의 참가자를 속일 수 있었던 반면에 그 외 모든 baseline 모델은 참가자를 거의 속일 수 없었습니다.</p>
<ul class="simple">
<li><p>FCN Score *</p></li>
</ul>
<figure class="align-default" id="id12">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqzYO1%2Fbtr728xs5iD%2FN5NDNYwUYLnEZfnOVYONM0%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqzYO1%2Fbtr728xs5iD%2FN5NDNYwUYLnEZfnOVYONM0%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqzYO1%2Fbtr728xs5iD%2FN5NDNYwUYLnEZfnOVYONM0%2Fimg.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 56 </span><span class="caption-text">FCN scores</span><a class="headerlink" href="#id12" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Table 2, Table 3 는 각각 도시 풍경에 대한 label -&gt; photo, 그리고 photo -&gt; label translation task 의 성능을 보여줍니다. 두 경우 모두 CycleGAN 이 baseline 들의 성능을 능가합니다.</p>
</section>
<section id="ablation-study-analysis-of-the-loss-function">
<h3>Ablation Study - Analysis of the loss function<a class="headerlink" href="#ablation-study-analysis-of-the-loss-function" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id13">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjQ9QQ%2Fbtr79farEX8%2FkQ6SWARw9QK9jqRqHlZoi1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjQ9QQ%2Fbtr79farEX8%2FkQ6SWARw9QK9jqRqHlZoi1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjQ9QQ%2Fbtr79farEX8%2FkQ6SWARw9QK9jqRqHlZoi1%2Fimg.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 57 </span><span class="caption-text">Analysis of loss function</span><a class="headerlink" href="#id13" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>GAN 과 cycle consistency loss 의 중요성을 보여주는 ablation study 입니다. GAN loss 그리고 cycle consistency loss 를 각각 제거하면 성능이 크게 저하되는 부분을 확인할 수 있습니다. 또한 한쪽 방향에 대해서만 GAN + forward cycle 만 돌렸을 때와 GAN + backward cycle 만 돌렸을 때 학습의 불안정성을 보이고, mode collapse 를 유발하는 것을 확인할 수 있었다고 합니다.</p>
</section>
<section id="image-reconstruction-quality">
<h3>Image reconstruction quality<a class="headerlink" href="#image-reconstruction-quality" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id14">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fyy7lt%2Fbtr73PdbuJp%2F5bmDtKSlQJJnd5yKvPgfB1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fyy7lt%2Fbtr73PdbuJp%2F5bmDtKSlQJJnd5yKvPgfB1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fyy7lt%2Fbtr73PdbuJp%2F5bmDtKSlQJJnd5yKvPgfB1%2Fimg.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 58 </span><span class="caption-text">Results on Cycle Consistency</span><a class="headerlink" href="#id14" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Reconctructed 된 이미지 예시들입니다. 지도 -&gt; 항공 사진과 같이 하나의 도메인이 훨씬 더 다양한 정보를 나타내는 경우에도 재구성된 이미지가 훈련 및 테스트 시 모두 원래 입력 <span class="math notranslate nohighlight">\(x\)</span> 에 가깝게 복원되는 경우가 많았습니다.</p>
</section>
<section id="additional-results-on-paired-datasets">
<h3>Additional results on paired datasets<a class="headerlink" href="#additional-results-on-paired-datasets" title="Permalink to this heading">#</a></h3>
<figure class="align-default" id="id15">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqNrhb%2Fbtr72YaInQa%2Fk8b4K99KrAsD9C0SHINtt1%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqNrhb%2Fbtr72YaInQa%2Fk8b4K99KrAsD9C0SHINtt1%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqNrhb%2Fbtr72YaInQa%2Fk8b4K99KrAsD9C0SHINtt1%2Fimg.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 59 </span><span class="caption-text">Additional results on paired datasets</span><a class="headerlink" href="#id15" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Figure 8 은 CMP Facade Database 의 건축 레이블 &lt;-&gt; 사진, 그리고 UT Zapoos50K dataset 의 edge &lt;-&gt; 신발 을 비롯하여 pix2pix 에 사용된 paired dataset 에 대한 몇 가지 예시 결과를 보여줍니다. CycleGAN 이 생성한 이미지 품질이 fully supervised 된 pix2pix 에 대응하는 성능을 보여주는 것을 확인할 수 있습니다.</p>
<!---->
<!--## Applications-->
<!---->
<!--Paired data 가 없는 상태에서 CycleGAN 의 application 예시 결과들입니다. -->
<!---->
<!--### Collection style transfer-->
<!---->
<!--Neural Style Transfer 에 대한 최근 작업과 달리, CycleGAN 은 선택한 단일 예술 작품의 스타일을 전달하는 대신 전체 예술 작품 컬렉션의 스타일을 모방하는 방법을 학습합니다. 그래서 '별이 빛나는 밤에'처럼 그리는 것 보다 '반 고흐'를 따라하는 느낌을 따라한다.-->
<!---->
<!--### Object transfiguration-->
<!---->
<!---->
<!--Turmukhambetov et al. \[50\] 하나의 객체를 동일한 범주의 다른 객체로 변환하는 부분 공간 모델을 제안하는 반면, 우리의 방법은 시각적으로 유사한 두 범주 사이의 객체 변형에 중점을 둡니다.  -->
<!--Turning a horse video into a zebra video (by CycleGAN)-->
<!---->
<!--### Season transfer-->
<!---->
<!---->
<!--### Photo generation from paintings-->
<!---->
<!---->
<!--그림을 사진으로 바꿀 때, 입력과 출력 간 색 구성을 보존하기 위해 추가적인 loss를 도입하는 것이 유용하다는 것을 발견할 수 있습니다. 특히, Taigman et al. \[49\]의 기술을 채택하여 제너레이터가 대상 도메인의 실제 샘플을 입력으로 제공받을 때 identity mapping 근처에 있도록 정규화합니다. 즉, **Lidentity(G,F) = Ey\_pdata(y)\[∥G(y) − y∥1\] + Ex∼pdata (x) \[∥F (x) − x∥1 \]**입니다.-->
<!---->
<!--Lidentity가 없으면, 생성자 G와 F는 굳이 필요하지 않을 때 입력 이미지의 색조를 자유롭게 변경할 수 있습니다. 예를 들어, Monet의 그림과 Flickr 사진 간의 매핑을 학습할 때, 생성자는 종종 낮에 그린 그림을 일몰 시간에 찍은 사진에 매핑합니다. 왜냐하면 적대적 손실과 사이클 일관성 손실 아래에서 이러한 매핑이 동등하게 유효할 수 있기 때문입니다. 이러한 identity mapping 손실의 효과는 그림 9에서 보여집니다. figure 12, figure 9는 학습 데이터셋에 포함되어 있는 그림, 하지만 다른 set은 오직 test set으로부터 그려진 그림. training set이 paired datqa를 포함하고 있지 않아서, 학습 세트 그림에 대한 타당한 translation을 찾는 것은 쉬운 일이 아니다. 실제로, Monet이 새 그림을 그릴 수 없기 때문에, 보지 않은 test set 그림에 대한 generalization은 not pressing problem-->
<!---->
<!--### Photo enhancement-->
<!---->
<!--우리는 우리의 방법이 얕은 깊이의 초점을 가진 사진을 생성하는 데 사용될 수 있음을 보여줍니다. 우리는 Flickr에서 다운로드한 꽃 사진을 기반으로 모델을 훈련합니다. 소스 도메인은 스마트폰으로 찍힌 꽃 사진으로 구성되어 있으며, 보통 작은 조리개로 인해 깊은 DoF(초점 깊이)를 가지고 있습니다. 대상은 조리개가 큰 DSLR로 촬영된 사진을 포함합니다. 우리 모델은 스마트폰으로 촬영된 사진으로부터 더 얕은 깊이의 초점을 가진 사진을 성공적으로 생성합니다.-->
<!---->
<!--> : shallow depth of field: 얕은 초점. 초점이 맞은 대상과 배경이 흐릿하게 보이는 효과. 인물 사진 / 작품 사진에 활용. 구목하고자 하는 대상을 강조하기 위해 활용.  -->
<!--> 따라서 source domain은 스마트폰의 **작은 조리개로 깊은 초점** \--> target은 **조리개가 커서 얕은 초점**.-->
<!---->
<!--### Comparison with Gatys-->
</section>
</section>
<section id="limitations-and-discusssion">
<h2>Limitations and Discusssion<a class="headerlink" href="#limitations-and-discusssion" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="id16">
<a class="bg-primary mb-1 reference internal image-reference" href="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdJc1k5%2Fbtr76zUPUWj%2F27Mk0oQ5VanEHANWWmaseK%2Fimg.png"><img alt="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdJc1k5%2Fbtr76zUPUWj%2F27Mk0oQ5VanEHANWWmaseK%2Fimg.png" class="bg-primary mb-1" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdJc1k5%2Fbtr76zUPUWj%2F27Mk0oQ5VanEHANWWmaseK%2Fimg.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 60 </span><span class="caption-text">Limitations and Discussion</span><a class="headerlink" href="#id16" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>이 방법은 많은 경우에 흥미로운 결과를 얻을 수 있지만, 결과가 균일하게 좋은 것은 아니었습니다.</p>
<ol class="arabic simple">
<li><p>개 &lt;-&gt; 고양이 translation task 와 같은 경우는 input image 에서 최소한의 변화만 주어, 사람이 보았을 때 실제로 변화가 안되는 경우도 있었고, 형체가 애매해진 경우도 있었습니다. 이를 보았을 때, geometry 가 반영되는 눈, 코, 입 등의 세부적인 구조에 대한 정확히 구현하는데 한계가 있어 보입니다.</p></li>
<li><p>말 &lt;–&gt; 얼룩말 translation 예제의 경우, 말은 사람이 타는 모습이 많았는데 얼룩말의 경우는 사람이 타는 사진이 없다보니, 사람 뿐만 아니라 배경도 얼룩 그림을 그리거나 단순히 얼룩말에서 노랗게 칠한 경우가 존재합니다.</p></li>
<li><p>때때로 photo -&gt; image translation task 에서 나무와 건물의 label 을 바꾸는 경우도 있었습니다.<br />
이러한 모호성을 해결하려면 weak semantic supervision 이 필요할 수도 있을 것 같습니다.</p></li>
</ol>
<p>그럼에도 불구하고 해당 논문은 완전히 paired 되지 않은 “unsupervised” setting 에서도 image translation task 의 한계를 늘리는데 기여합니다.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/review"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="A_Study_on_the_Evaluation_of_Generative_Models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">A Study on the Evaluation of Generative Models</p>
      </div>
    </a>
    <a class="right-next"
       href="StyleGAN.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">StyleGAN</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#related-work">Related work</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-to-image-translation">Image-to-Image Translation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mode-collapse">Mode Collapse</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#method">Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adversarial-loss">Adversarial Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cycle-consistency-loss">Cycle Consistency Loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#full-objective">Full Objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network-architecture">Network Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-details">Training details</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#least-square-loss">(참고) least-square loss 추가 설명</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-against-baselines">Comparison against baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ablation-study-analysis-of-the-loss-function">Ablation Study - Analysis of the loss function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-reconstruction-quality">Image reconstruction quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-results-on-paired-datasets">Additional results on paired datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-discusssion">Limitations and Discusssion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By PseudoLab
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>